{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f3ea7110",
      "metadata": {
        "id": "f3ea7110"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle as pkl\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, BatchNormalization, Dropout\n",
        "from keras.optimizers import Adam, SGD, RMSprop, Adadelta, Adagrad, Adamax, Nadam, Ftrl\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from math import floor\n",
        "from sklearn.metrics import make_scorer, accuracy_score, mean_squared_error, mean_absolute_error, r2_score\n",
        "from bayes_opt import BayesianOptimization\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "pd.set_option(\"display.max_columns\", None)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f168c579",
      "metadata": {
        "id": "f168c579"
      },
      "source": [
        "**IMPORT & PREPARE DATA**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3010acda",
      "metadata": {
        "id": "3010acda"
      },
      "outputs": [],
      "source": [
        "X_train = pd.read_csv(\"X_train.csv\")\n",
        "X_test = pd.read_csv(\"X_test.csv\")\n",
        "y_train = pd.read_csv(\"y_train.csv\")\n",
        "y_test = pd.read_csv(\"y_test.csv\")\n",
        "\n",
        "X_train = X_train.drop(columns=['Unnamed: 0'])\n",
        "X_test = X_test.drop(columns=['Unnamed: 0'])\n",
        "y_train = y_train.drop(columns=['Unnamed: 0'])\n",
        "y_test = y_test.drop(columns=['Unnamed: 0'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a70741a",
      "metadata": {
        "id": "6a70741a"
      },
      "outputs": [],
      "source": [
        "with open('scaler.pkl', 'rb') as f:\n",
        "    scaler = pkl.load(f)\n",
        "\n",
        "with open('selectkbest_f_regression.pkl', 'rb') as f:\n",
        "    selectkbest_f_regression = pkl.load(f)\n",
        "\n",
        "with open('selectkbest_mutual_info_regression.pkl', 'rb') as f:\n",
        "    selectkbest_mutual_info_regression = pkl.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "91f16818",
      "metadata": {
        "id": "91f16818"
      },
      "outputs": [],
      "source": [
        "# Scale\n",
        "X_train_scaled_arr = scaler.transform(X_train)\n",
        "X_test_scaled_arr = scaler.transform(X_test)\n",
        "\n",
        "# SelectKBest\n",
        "X_train_f_reg_arr = selectkbest_f_regression.transform(X_train)\n",
        "X_test_f_reg_arr = selectkbest_f_regression.transform(X_test)\n",
        "\n",
        "# SelectKBest\n",
        "X_train_mi_reg_arr = selectkbest_mutual_info_regression.transform(X_train)\n",
        "X_test_mi_reg_arr = selectkbest_mutual_info_regression.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "94d86645",
      "metadata": {
        "id": "94d86645"
      },
      "outputs": [],
      "source": [
        "columns_scaled = ['crime_rate_ranking', 'area', 'contractMonth', 'distance_from_nearest_stop', 'nearest_mrt_walking_time', 'nearest_stop_num', 'nearest_taxi_stand_walking_time', 'ave_level',\n",
        "                  'contractYear', 'rating', 'marketSegment_CCR', 'marketSegment_OCR', 'marketSegment_RCR', 'propertyType_Apartment', 'propertyType_Condominium', 'propertyType_Detached',\n",
        "                  'propertyType_Semi-detached', 'propertyType_Strata Detached', 'propertyType_Strata Semi-detached', 'propertyType_Strata Terrace', 'propertyType_Terrace', 'typeOfArea_Land',\n",
        "                  'typeOfArea_Strata', 'nearest_mrt_BENCOOLEN MRT STATION (DT21)', 'nearest_mrt_BUGIS MRT STATION (DT14)', 'nearest_mrt_BUONA VISTA MRT STATION (CC22)', 'nearest_mrt_BUONA VISTA MRT STATION (EW21)',\n",
        "                  'nearest_mrt_CHINATOWN MRT STATION (NE4)', 'nearest_mrt_CITY HALL MRT STATION (EW13 / NS25)', 'nearest_mrt_CLARKE QUAY MRT STATION (NE5)', 'nearest_mrt_CLEMENTI MRT STATION (EW23)',\n",
        "                  'nearest_mrt_COMMONWEALTH MRT STATION (EW20)', 'nearest_mrt_DOWNTOWN MRT STATION (DT17)', 'nearest_mrt_ESPLANADE MRT STATION (CC3)', 'nearest_mrt_FORT CANNING MRT STATION (DT20)',\n",
        "                  'nearest_mrt_GREAT WORLD MRT STATION (TE15)', 'nearest_mrt_HARBOURFRONT MRT STATION (NE1 / CC29)', 'nearest_mrt_HAVELOCK MRT STATION (TE16)', 'nearest_mrt_HAW PAR VILLA MRT STATION (CC25)',\n",
        "                  'nearest_mrt_KENT RIDGE MRT STATION (CC24)', 'nearest_mrt_KOVAN MRT STATION (NE13)', 'nearest_mrt_LABRADOR PARK MRT STATION (CC27)', 'nearest_mrt_LAVENDER MRT STATION (EW11)',\n",
        "                  'nearest_mrt_LITTLE INDIA MRT STATION (NE7)', 'nearest_mrt_MARINA BAY MRT STATION (NS27)', 'nearest_mrt_MARINA BAY MRT STATION (TE20)', 'nearest_mrt_MARINA SOUTH PIER MRT STATION (NS28)',\n",
        "                  'nearest_mrt_MAXWELL MRT STATION (TE18)', 'nearest_mrt_NICOLL HIGHWAY MRT STATION (CC5)', 'nearest_mrt_ONE-NORTH MRT STATION (CC23)', 'nearest_mrt_OUTRAM PARK MRT STATION (EW16)',\n",
        "                  'nearest_mrt_OUTRAM PARK MRT STATION (NE3)', 'nearest_mrt_PASIR PANJANG MRT STATION (CC26)', 'nearest_mrt_QUEENSTOWN MRT STATION (EW19)', 'nearest_mrt_REDHILL MRT STATION (EW18)',\n",
        "                  'nearest_mrt_ROCHOR MRT STATION (DT13)', 'nearest_mrt_SHENTON WAY MRT STATION (TE19)', 'nearest_mrt_TANJONG PAGAR MRT STATION (EW15)', 'nearest_mrt_TELOK AYER MRT STATION (DT18)',\n",
        "                  'nearest_mrt_TELOK BLANGAH MRT STATION (CC28)', 'nearest_mrt_TIONG BAHRU MRT STATION (EW17)', 'typeOfSale_1', 'typeOfSale_2', 'typeOfSale_3', 'district_1', 'district_2',\n",
        "                  'district_3', 'district_4', 'district_5', 'district_6', 'district_7', 'tenure_cat_1', 'tenure_cat_2', 'tenure_cat_3']\n",
        "X_train_scaled = pd.DataFrame(X_train_scaled_arr, columns=columns_scaled)\n",
        "X_test_scaled = pd.DataFrame(X_test_scaled_arr, columns=columns_scaled)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ff20e51a",
      "metadata": {
        "id": "ff20e51a"
      },
      "source": [
        "# WITHOUT SCALED TRAINING DATA"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "75517ccc",
      "metadata": {
        "id": "75517ccc"
      },
      "source": [
        "**BUILD THE MODEL**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "55c35c0e",
      "metadata": {
        "id": "55c35c0e"
      },
      "source": [
        "**Hyperparameter Tuning**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "97a0e7bb",
      "metadata": {
        "id": "97a0e7bb"
      },
      "outputs": [],
      "source": [
        "# Make scorer accuracy\n",
        "score_acc = make_scorer(mean_squared_error)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "43fbf65e",
      "metadata": {
        "id": "43fbf65e"
      },
      "outputs": [],
      "source": [
        "def function1(neurons, activation, optimizer, learning_rate, batch_size, epochs,\n",
        "              layers1, layers2, normalization, dropout, dropout_rate):\n",
        "    optimizerL = ['Adam', 'Adam'] #Fixing the optimizer to Adam\n",
        "    optimizerD= {'Adam':Adam(lr=learning_rate)}\n",
        "    activationL = ['relu', 'relu'] #Fixing the activation to relu\n",
        "    neurons = round(neurons)\n",
        "    activation = activationL[round(activation)]\n",
        "    optimizer = optimizerD[optimizerL[round(optimizer)]]\n",
        "    batch_size = round(batch_size)\n",
        "    epochs = round(epochs)\n",
        "    layers1 = round(layers1)\n",
        "    layers2 = round(layers2)\n",
        "    def nn_cl_fun():\n",
        "        nn = Sequential()\n",
        "        nn.add(Dense(neurons, input_dim=74, activation=activation))\n",
        "        if normalization > 0.5:\n",
        "            nn.add(BatchNormalization())\n",
        "        for i in range(layers1):\n",
        "            nn.add(Dense(neurons, activation=activation))\n",
        "        if dropout > 0.5:\n",
        "            nn.add(Dropout(dropout_rate, seed=2023))\n",
        "        for i in range(layers2):\n",
        "            nn.add(Dense(neurons, activation=activation))\n",
        "        nn.add(Dense(1))\n",
        "        nn.compile(loss='mse', optimizer=optimizer, metrics=['mse'])\n",
        "        return nn\n",
        "    es = EarlyStopping(monitor='mse', mode='min', verbose=0, patience=20)\n",
        "    nn = KerasClassifier(build_fn=nn_cl_fun, epochs=epochs, batch_size=batch_size, verbose=0)\n",
        "    kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=2023)\n",
        "    score = cross_val_score(nn, X_train, y_train, scoring=score_acc, cv=kfold, fit_params={'callbacks':[es]}).mean()\n",
        "    return score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b513eac1",
      "metadata": {
        "scrolled": true,
        "id": "b513eac1",
        "outputId": "b3e3bd56-ad7c-4dbe-b8a6-62b546037c27"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "|   iter    |  target   | activa... | batch_... |  dropout  | dropou... |  epochs   |  layers1  |  layers2  | learni... |  neurons  | normal... | optimizer |\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "119/119 [==============================] - 0s 458us/step\n",
            "119/119 [==============================] - 0s 441us/step\n",
            "119/119 [==============================] - 0s 467us/step\n",
            "119/119 [==============================] - 0s 450us/step\n",
            "119/119 [==============================] - 0s 450us/step\n",
            "| \u001b[0m1        \u001b[0m | \u001b[0m2.22e+13 \u001b[0m | \u001b[0m0.3288   \u001b[0m | \u001b[0m912.3    \u001b[0m | \u001b[0m0.5881   \u001b[0m | \u001b[0m0.03798  \u001b[0m | \u001b[0m31.31    \u001b[0m | \u001b[0m2.872    \u001b[0m | \u001b[0m1.088    \u001b[0m | \u001b[0m0.73     \u001b[0m | \u001b[0m57.19    \u001b[0m | \u001b[0m0.5449   \u001b[0m | \u001b[0m0.4564   \u001b[0m |\n",
            "119/119 [==============================] - 0s 450us/step\n",
            "119/119 [==============================] - 0s 450us/step\n",
            "119/119 [==============================] - 0s 458us/step\n",
            "119/119 [==============================] - 0s 443us/step\n",
            "119/119 [==============================] - 0s 441us/step\n",
            "| \u001b[0m2        \u001b[0m | \u001b[0m2.22e+13 \u001b[0m | \u001b[0m0.5064   \u001b[0m | \u001b[0m515.6    \u001b[0m | \u001b[0m0.1512   \u001b[0m | \u001b[0m0.1083   \u001b[0m | \u001b[0m32.97    \u001b[0m | \u001b[0m2.352    \u001b[0m | \u001b[0m1.721    \u001b[0m | \u001b[0m0.3971   \u001b[0m | \u001b[0m13.21    \u001b[0m | \u001b[0m0.5649   \u001b[0m | \u001b[0m0.2035   \u001b[0m |\n",
            "119/119 [==============================] - 0s 467us/step\n",
            "119/119 [==============================] - 0s 467us/step\n",
            "119/119 [==============================] - 0s 458us/step\n",
            "119/119 [==============================] - 0s 467us/step\n",
            "119/119 [==============================] - 0s 475us/step\n",
            "| \u001b[95m3        \u001b[0m | \u001b[95m2.224e+13\u001b[0m | \u001b[95m0.3274   \u001b[0m | \u001b[95m501.3    \u001b[0m | \u001b[95m0.1841   \u001b[0m | \u001b[95m0.03119  \u001b[0m | \u001b[95m56.39    \u001b[0m | \u001b[95m1.783    \u001b[0m | \u001b[95m2.514    \u001b[0m | \u001b[95m0.9312   \u001b[0m | \u001b[95m78.41    \u001b[0m | \u001b[95m0.7708   \u001b[0m | \u001b[95m0.5967   \u001b[0m |\n",
            "119/119 [==============================] - 0s 450us/step\n",
            "119/119 [==============================] - 0s 458us/step\n",
            "119/119 [==============================] - 0s 450us/step\n",
            "119/119 [==============================] - 0s 459us/step\n",
            "119/119 [==============================] - 0s 450us/step\n",
            "| \u001b[0m4        \u001b[0m | \u001b[0m2.224e+13\u001b[0m | \u001b[0m0.7937   \u001b[0m | \u001b[0m848.3    \u001b[0m | \u001b[0m0.9806   \u001b[0m | \u001b[0m0.2654   \u001b[0m | \u001b[0m28.78    \u001b[0m | \u001b[0m4.279    \u001b[0m | \u001b[0m2.23     \u001b[0m | \u001b[0m0.2689   \u001b[0m | \u001b[0m46.52    \u001b[0m | \u001b[0m0.5534   \u001b[0m | \u001b[0m0.6255   \u001b[0m |\n",
            "119/119 [==============================] - 0s 441us/step\n",
            "119/119 [==============================] - 0s 438us/step\n",
            "119/119 [==============================] - 0s 433us/step\n",
            "119/119 [==============================] - 0s 433us/step\n",
            "119/119 [==============================] - 0s 433us/step\n",
            "| \u001b[0m5        \u001b[0m | \u001b[0m2.224e+13\u001b[0m | \u001b[0m0.08797  \u001b[0m | \u001b[0m977.8    \u001b[0m | \u001b[0m0.4113   \u001b[0m | \u001b[0m0.2165   \u001b[0m | \u001b[0m73.06    \u001b[0m | \u001b[0m1.873    \u001b[0m | \u001b[0m1.749    \u001b[0m | \u001b[0m0.7325   \u001b[0m | \u001b[0m87.7     \u001b[0m | \u001b[0m0.3917   \u001b[0m | \u001b[0m0.11     \u001b[0m |\n",
            "119/119 [==============================] - 0s 483us/step\n",
            "119/119 [==============================] - 0s 509us/step\n",
            "119/119 [==============================] - 0s 500us/step\n",
            "119/119 [==============================] - 0s 500us/step\n",
            "119/119 [==============================] - 0s 509us/step\n",
            "| \u001b[0m6        \u001b[0m | \u001b[0m2.224e+13\u001b[0m | \u001b[0m0.9137   \u001b[0m | \u001b[0m485.6    \u001b[0m | \u001b[0m0.413    \u001b[0m | \u001b[0m0.05506  \u001b[0m | \u001b[0m66.88    \u001b[0m | \u001b[0m4.423    \u001b[0m | \u001b[0m4.159    \u001b[0m | \u001b[0m0.09696  \u001b[0m | \u001b[0m93.97    \u001b[0m | \u001b[0m0.5      \u001b[0m | \u001b[0m0.3643   \u001b[0m |\n",
            "119/119 [==============================] - 0s 441us/step\n",
            "119/119 [==============================] - 0s 458us/step\n",
            "119/119 [==============================] - 0s 450us/step\n",
            "119/119 [==============================] - 0s 433us/step\n",
            "119/119 [==============================] - 0s 442us/step\n",
            "| \u001b[0m7        \u001b[0m | \u001b[0m2.223e+13\u001b[0m | \u001b[0m0.4888   \u001b[0m | \u001b[0m612.2    \u001b[0m | \u001b[0m0.9946   \u001b[0m | \u001b[0m0.226    \u001b[0m | \u001b[0m49.27    \u001b[0m | \u001b[0m3.445    \u001b[0m | \u001b[0m2.678    \u001b[0m | \u001b[0m0.1008   \u001b[0m | \u001b[0m58.14    \u001b[0m | \u001b[0m0.3408   \u001b[0m | \u001b[0m0.01834  \u001b[0m |\n",
            "119/119 [==============================] - 0s 450us/step\n",
            "119/119 [==============================] - 0s 424us/step\n",
            "119/119 [==============================] - 0s 450us/step\n",
            "119/119 [==============================] - 0s 450us/step\n",
            "119/119 [==============================] - 0s 433us/step\n",
            "| \u001b[0m8        \u001b[0m | \u001b[0m2.22e+13 \u001b[0m | \u001b[0m0.6074   \u001b[0m | \u001b[0m937.4    \u001b[0m | \u001b[0m0.2814   \u001b[0m | \u001b[0m0.2504   \u001b[0m | \u001b[0m63.97    \u001b[0m | \u001b[0m1.087    \u001b[0m | \u001b[0m2.388    \u001b[0m | \u001b[0m0.5545   \u001b[0m | \u001b[0m11.19    \u001b[0m | \u001b[0m0.7159   \u001b[0m | \u001b[0m0.1898   \u001b[0m |\n",
            "119/119 [==============================] - 0s 492us/step\n",
            "119/119 [==============================] - 0s 475us/step\n",
            "119/119 [==============================] - 0s 483us/step\n",
            "119/119 [==============================] - 0s 492us/step\n",
            "119/119 [==============================] - 0s 483us/step\n",
            "| \u001b[0m9        \u001b[0m | \u001b[0m2.224e+13\u001b[0m | \u001b[0m0.745    \u001b[0m | \u001b[0m703.5    \u001b[0m | \u001b[0m0.3622   \u001b[0m | \u001b[0m0.1881   \u001b[0m | \u001b[0m61.19    \u001b[0m | \u001b[0m4.58     \u001b[0m | \u001b[0m3.075    \u001b[0m | \u001b[0m0.6113   \u001b[0m | \u001b[0m52.73    \u001b[0m | \u001b[0m0.7096   \u001b[0m | \u001b[0m0.1152   \u001b[0m |\n",
            "119/119 [==============================] - 0s 467us/step\n",
            "119/119 [==============================] - 0s 458us/step\n",
            "119/119 [==============================] - 0s 467us/step\n",
            "119/119 [==============================] - 0s 475us/step\n",
            "119/119 [==============================] - 0s 455us/step\n",
            "| \u001b[0m10       \u001b[0m | \u001b[0m2.224e+13\u001b[0m | \u001b[0m0.7355   \u001b[0m | \u001b[0m902.4    \u001b[0m | \u001b[0m0.5191   \u001b[0m | \u001b[0m0.2041   \u001b[0m | \u001b[0m54.84    \u001b[0m | \u001b[0m4.887    \u001b[0m | \u001b[0m2.461    \u001b[0m | \u001b[0m0.6265   \u001b[0m | \u001b[0m33.25    \u001b[0m | \u001b[0m0.6813   \u001b[0m | \u001b[0m0.8766   \u001b[0m |\n",
            "119/119 [==============================] - 0s 450us/step\n",
            "119/119 [==============================] - 0s 450us/step\n",
            "119/119 [==============================] - 0s 458us/step\n",
            "119/119 [==============================] - 0s 433us/step\n",
            "119/119 [==============================] - 0s 450us/step\n",
            "| \u001b[0m11       \u001b[0m | \u001b[0m2.224e+13\u001b[0m | \u001b[0m0.2498   \u001b[0m | \u001b[0m314.1    \u001b[0m | \u001b[0m0.8254   \u001b[0m | \u001b[0m0.1396   \u001b[0m | \u001b[0m47.05    \u001b[0m | \u001b[0m4.735    \u001b[0m | \u001b[0m2.818    \u001b[0m | \u001b[0m0.4993   \u001b[0m | \u001b[0m14.13    \u001b[0m | \u001b[0m0.119    \u001b[0m | \u001b[0m0.538    \u001b[0m |\n",
            "119/119 [==============================] - 0s 475us/step\n",
            "119/119 [==============================] - 0s 475us/step\n",
            "119/119 [==============================] - 0s 475us/step\n",
            "119/119 [==============================] - 0s 475us/step\n",
            "119/119 [==============================] - 0s 500us/step\n",
            "| \u001b[0m12       \u001b[0m | \u001b[0m2.224e+13\u001b[0m | \u001b[0m0.06424  \u001b[0m | \u001b[0m440.4    \u001b[0m | \u001b[0m0.3781   \u001b[0m | \u001b[0m0.1827   \u001b[0m | \u001b[0m85.91    \u001b[0m | \u001b[0m1.732    \u001b[0m | \u001b[0m4.148    \u001b[0m | \u001b[0m0.3183   \u001b[0m | \u001b[0m79.44    \u001b[0m | \u001b[0m0.9149   \u001b[0m | \u001b[0m0.2263   \u001b[0m |\n",
            "119/119 [==============================] - 0s 496us/step\n",
            "119/119 [==============================] - 0s 509us/step\n",
            "119/119 [==============================] - 0s 492us/step\n",
            "119/119 [==============================] - 0s 483us/step\n",
            "119/119 [==============================] - 0s 517us/step\n",
            "| \u001b[0m13       \u001b[0m | \u001b[0m2.224e+13\u001b[0m | \u001b[0m0.9912   \u001b[0m | \u001b[0m449.2    \u001b[0m | \u001b[0m0.8856   \u001b[0m | \u001b[0m0.2081   \u001b[0m | \u001b[0m24.36    \u001b[0m | \u001b[0m1.807    \u001b[0m | \u001b[0m4.437    \u001b[0m | \u001b[0m0.6641   \u001b[0m | \u001b[0m88.55    \u001b[0m | \u001b[0m0.7237   \u001b[0m | \u001b[0m0.09194  \u001b[0m |\n",
            "119/119 [==============================] - 0s 424us/step\n",
            "119/119 [==============================] - 0s 424us/step\n",
            "119/119 [==============================] - 0s 433us/step\n",
            "119/119 [==============================] - 0s 433us/step\n",
            "119/119 [==============================] - 0s 441us/step\n",
            "| \u001b[0m14       \u001b[0m | \u001b[0m2.224e+13\u001b[0m | \u001b[0m0.03175  \u001b[0m | \u001b[0m345.6    \u001b[0m | \u001b[0m0.2761   \u001b[0m | \u001b[0m0.202    \u001b[0m | \u001b[0m65.64    \u001b[0m | \u001b[0m2.509    \u001b[0m | \u001b[0m2.138    \u001b[0m | \u001b[0m0.2106   \u001b[0m | \u001b[0m39.78    \u001b[0m | \u001b[0m0.3645   \u001b[0m | \u001b[0m0.2026   \u001b[0m |\n",
            "119/119 [==============================] - 0s 483us/step\n",
            "119/119 [==============================] - 0s 492us/step\n",
            "119/119 [==============================] - 0s 492us/step\n",
            "119/119 [==============================] - 0s 483us/step\n",
            "119/119 [==============================] - 0s 492us/step\n",
            "| \u001b[0m15       \u001b[0m | \u001b[0m2.224e+13\u001b[0m | \u001b[0m0.6069   \u001b[0m | \u001b[0m250.4    \u001b[0m | \u001b[0m0.7315   \u001b[0m | \u001b[0m0.2202   \u001b[0m | \u001b[0m67.21    \u001b[0m | \u001b[0m3.868    \u001b[0m | \u001b[0m3.853    \u001b[0m | \u001b[0m0.7781   \u001b[0m | \u001b[0m71.56    \u001b[0m | \u001b[0m0.7979   \u001b[0m | \u001b[0m0.589    \u001b[0m |\n",
            "119/119 [==============================] - 0s 458us/step\n",
            "119/119 [==============================] - 0s 450us/step\n",
            "119/119 [==============================] - 0s 450us/step\n",
            "119/119 [==============================] - 0s 441us/step\n",
            "119/119 [==============================] - 0s 450us/step\n",
            "| \u001b[0m16       \u001b[0m | \u001b[0m2.22e+13 \u001b[0m | \u001b[0m0.8611   \u001b[0m | \u001b[0m553.8    \u001b[0m | \u001b[0m0.388    \u001b[0m | \u001b[0m0.08434  \u001b[0m | \u001b[0m27.63    \u001b[0m | \u001b[0m2.734    \u001b[0m | \u001b[0m3.705    \u001b[0m | \u001b[0m0.2582   \u001b[0m | \u001b[0m40.57    \u001b[0m | \u001b[0m0.6354   \u001b[0m | \u001b[0m0.681    \u001b[0m |\n",
            "119/119 [==============================] - 0s 492us/step\n",
            "119/119 [==============================] - 0s 517us/step\n",
            "119/119 [==============================] - 0s 560us/step\n",
            "119/119 [==============================] - 0s 509us/step\n",
            "119/119 [==============================] - 0s 517us/step\n",
            "| \u001b[0m17       \u001b[0m | \u001b[0m2.224e+13\u001b[0m | \u001b[0m0.3567   \u001b[0m | \u001b[0m604.8    \u001b[0m | \u001b[0m0.4119   \u001b[0m | \u001b[0m0.2227   \u001b[0m | \u001b[0m31.6     \u001b[0m | \u001b[0m3.925    \u001b[0m | \u001b[0m3.062    \u001b[0m | \u001b[0m0.3393   \u001b[0m | \u001b[0m93.31    \u001b[0m | \u001b[0m0.9734   \u001b[0m | \u001b[0m0.5595   \u001b[0m |\n",
            "119/119 [==============================] - 0s 534us/step\n",
            "119/119 [==============================] - 0s 534us/step\n",
            "119/119 [==============================] - 0s 543us/step\n",
            "119/119 [==============================] - 0s 534us/step\n",
            "119/119 [==============================] - 0s 541us/step\n",
            "| \u001b[0m18       \u001b[0m | \u001b[0m2.224e+13\u001b[0m | \u001b[0m0.1109   \u001b[0m | \u001b[0m737.7    \u001b[0m | \u001b[0m0.9307   \u001b[0m | \u001b[0m0.08556  \u001b[0m | \u001b[0m29.43    \u001b[0m | \u001b[0m4.402    \u001b[0m | \u001b[0m3.782    \u001b[0m | \u001b[0m0.9006   \u001b[0m | \u001b[0m94.77    \u001b[0m | \u001b[0m0.5163   \u001b[0m | \u001b[0m0.6949   \u001b[0m |\n",
            "119/119 [==============================] - 0s 439us/step\n",
            "119/119 [==============================] - 0s 424us/step\n",
            "119/119 [==============================] - 0s 433us/step\n",
            "119/119 [==============================] - 0s 441us/step\n",
            "119/119 [==============================] - 0s 441us/step\n",
            "| \u001b[0m19       \u001b[0m | \u001b[0m2.22e+13 \u001b[0m | \u001b[0m0.4372   \u001b[0m | \u001b[0m899.2    \u001b[0m | \u001b[0m0.6551   \u001b[0m | \u001b[0m0.02753  \u001b[0m | \u001b[0m43.47    \u001b[0m | \u001b[0m2.187    \u001b[0m | \u001b[0m2.334    \u001b[0m | \u001b[0m0.1267   \u001b[0m | \u001b[0m63.06    \u001b[0m | \u001b[0m0.4873   \u001b[0m | \u001b[0m0.1037   \u001b[0m |\n",
            "119/119 [==============================] - 0s 475us/step\n",
            "119/119 [==============================] - 0s 450us/step\n",
            "119/119 [==============================] - 0s 441us/step\n",
            "119/119 [==============================] - 0s 470us/step\n",
            "119/119 [==============================] - 0s 450us/step\n",
            "| \u001b[0m20       \u001b[0m | \u001b[0m2.22e+13 \u001b[0m | \u001b[0m0.3013   \u001b[0m | \u001b[0m701.7    \u001b[0m | \u001b[0m0.07346  \u001b[0m | \u001b[0m0.05054  \u001b[0m | \u001b[0m76.62    \u001b[0m | \u001b[0m3.378    \u001b[0m | \u001b[0m3.057    \u001b[0m | \u001b[0m0.54     \u001b[0m | \u001b[0m33.33    \u001b[0m | \u001b[0m0.6661   \u001b[0m | \u001b[0m0.02819  \u001b[0m |\n",
            "119/119 [==============================] - 0s 475us/step\n",
            "119/119 [==============================] - 0s 450us/step\n",
            "119/119 [==============================] - 0s 458us/step\n",
            "119/119 [==============================] - 0s 475us/step\n",
            "119/119 [==============================] - 0s 475us/step\n",
            "| \u001b[0m21       \u001b[0m | \u001b[0m2.224e+13\u001b[0m | \u001b[0m0.6874   \u001b[0m | \u001b[0m667.3    \u001b[0m | \u001b[0m0.5589   \u001b[0m | \u001b[0m0.04195  \u001b[0m | \u001b[0m30.23    \u001b[0m | \u001b[0m3.178    \u001b[0m | \u001b[0m3.264    \u001b[0m | \u001b[0m0.8174   \u001b[0m | \u001b[0m41.98    \u001b[0m | \u001b[0m0.5924   \u001b[0m | \u001b[0m0.6753   \u001b[0m |\n",
            "119/119 [==============================] - 0s 473us/step\n",
            "119/119 [==============================] - 0s 467us/step\n",
            "119/119 [==============================] - 0s 475us/step\n",
            "119/119 [==============================] - 0s 458us/step\n",
            "119/119 [==============================] - 0s 441us/step\n",
            "| \u001b[0m22       \u001b[0m | \u001b[0m2.224e+13\u001b[0m | \u001b[0m0.09972  \u001b[0m | \u001b[0m783.9    \u001b[0m | \u001b[0m0.7164   \u001b[0m | \u001b[0m0.2642   \u001b[0m | \u001b[0m53.48    \u001b[0m | \u001b[0m1.875    \u001b[0m | \u001b[0m3.743    \u001b[0m | \u001b[0m0.9643   \u001b[0m | \u001b[0m61.84    \u001b[0m | \u001b[0m0.2376   \u001b[0m | \u001b[0m0.3408   \u001b[0m |\n",
            "119/119 [==============================] - 0s 450us/step\n",
            "119/119 [==============================] - 0s 450us/step\n",
            "119/119 [==============================] - 0s 441us/step\n",
            "119/119 [==============================] - 0s 467us/step\n",
            "119/119 [==============================] - 0s 458us/step\n",
            "| \u001b[0m23       \u001b[0m | \u001b[0m2.223e+13\u001b[0m | \u001b[0m0.6347   \u001b[0m | \u001b[0m741.3    \u001b[0m | \u001b[0m0.6444   \u001b[0m | \u001b[0m0.201    \u001b[0m | \u001b[0m66.52    \u001b[0m | \u001b[0m2.763    \u001b[0m | \u001b[0m3.407    \u001b[0m | \u001b[0m0.3842   \u001b[0m | \u001b[0m33.18    \u001b[0m | \u001b[0m0.9529   \u001b[0m | \u001b[0m0.5877   \u001b[0m |\n",
            "119/119 [==============================] - 0s 509us/step\n",
            "119/119 [==============================] - 0s 467us/step\n",
            "119/119 [==============================] - 0s 464us/step\n",
            "119/119 [==============================] - 0s 492us/step\n",
            "119/119 [==============================] - 0s 483us/step\n",
            "| \u001b[0m24       \u001b[0m | \u001b[0m2.224e+13\u001b[0m | \u001b[0m0.826    \u001b[0m | \u001b[0m594.4    \u001b[0m | \u001b[0m0.681    \u001b[0m | \u001b[0m0.1518   \u001b[0m | \u001b[0m38.07    \u001b[0m | \u001b[0m2.38     \u001b[0m | \u001b[0m4.119    \u001b[0m | \u001b[0m0.1059   \u001b[0m | \u001b[0m83.26    \u001b[0m | \u001b[0m0.1024   \u001b[0m | \u001b[0m0.6199   \u001b[0m |\n",
            "119/119 [==============================] - 0s 441us/step\n",
            "119/119 [==============================] - 0s 441us/step\n",
            "119/119 [==============================] - 0s 424us/step\n",
            "119/119 [==============================] - 0s 433us/step\n",
            "119/119 [==============================] - 0s 416us/step\n",
            "| \u001b[0m25       \u001b[0m | \u001b[0m2.224e+13\u001b[0m | \u001b[0m0.08354  \u001b[0m | \u001b[0m976.4    \u001b[0m | \u001b[0m0.6527   \u001b[0m | \u001b[0m0.2858   \u001b[0m | \u001b[0m76.45    \u001b[0m | \u001b[0m1.421    \u001b[0m | \u001b[0m2.57     \u001b[0m | \u001b[0m0.7721   \u001b[0m | \u001b[0m61.96    \u001b[0m | \u001b[0m0.3429   \u001b[0m | \u001b[0m0.02441  \u001b[0m |\n",
            "119/119 [==============================] - 0s 492us/step\n",
            "119/119 [==============================] - 0s 509us/step\n",
            "119/119 [==============================] - 0s 509us/step\n",
            "119/119 [==============================] - 0s 500us/step\n",
            "119/119 [==============================] - 0s 517us/step\n",
            "| \u001b[0m26       \u001b[0m | \u001b[0m2.224e+13\u001b[0m | \u001b[0m0.7875   \u001b[0m | \u001b[0m709.0    \u001b[0m | \u001b[0m0.646    \u001b[0m | \u001b[0m0.2188   \u001b[0m | \u001b[0m43.06    \u001b[0m | \u001b[0m4.917    \u001b[0m | \u001b[0m3.258    \u001b[0m | \u001b[0m0.7517   \u001b[0m | \u001b[0m71.22    \u001b[0m | \u001b[0m0.6489   \u001b[0m | \u001b[0m0.3801   \u001b[0m |\n",
            "119/119 [==============================] - 0s 477us/step\n",
            "119/119 [==============================] - 0s 475us/step\n",
            "119/119 [==============================] - 0s 472us/step\n",
            "119/119 [==============================] - 0s 475us/step\n",
            "119/119 [==============================] - 0s 467us/step\n",
            "| \u001b[0m27       \u001b[0m | \u001b[0m2.224e+13\u001b[0m | \u001b[0m0.827    \u001b[0m | \u001b[0m460.1    \u001b[0m | \u001b[0m0.3359   \u001b[0m | \u001b[0m0.2037   \u001b[0m | \u001b[0m54.28    \u001b[0m | \u001b[0m2.721    \u001b[0m | \u001b[0m2.742    \u001b[0m | \u001b[0m0.5083   \u001b[0m | \u001b[0m74.81    \u001b[0m | \u001b[0m0.8622   \u001b[0m | \u001b[0m0.1029   \u001b[0m |\n",
            "119/119 [==============================] - 0s 450us/step\n",
            "119/119 [==============================] - 0s 458us/step\n",
            "119/119 [==============================] - 0s 467us/step\n",
            "119/119 [==============================] - 0s 468us/step\n",
            "119/119 [==============================] - 0s 450us/step\n",
            "| \u001b[0m28       \u001b[0m | \u001b[0m2.224e+13\u001b[0m | \u001b[0m1.0      \u001b[0m | \u001b[0m876.5    \u001b[0m | \u001b[0m0.5411   \u001b[0m | \u001b[0m0.3      \u001b[0m | \u001b[0m58.53    \u001b[0m | \u001b[0m5.0      \u001b[0m | \u001b[0m2.749    \u001b[0m | \u001b[0m0.8857   \u001b[0m | \u001b[0m18.32    \u001b[0m | \u001b[0m0.8116   \u001b[0m | \u001b[0m1.0      \u001b[0m |\n",
            "119/119 [==============================] - 0s 458us/step\n",
            "119/119 [==============================] - 0s 475us/step\n",
            "119/119 [==============================] - 0s 464us/step\n",
            "119/119 [==============================] - 0s 458us/step\n",
            "119/119 [==============================] - 0s 458us/step\n",
            "| \u001b[0m29       \u001b[0m | \u001b[0m2.224e+13\u001b[0m | \u001b[0m0.6479   \u001b[0m | \u001b[0m977.2    \u001b[0m | \u001b[0m0.23     \u001b[0m | \u001b[0m0.1958   \u001b[0m | \u001b[0m74.54    \u001b[0m | \u001b[0m2.488    \u001b[0m | \u001b[0m2.223    \u001b[0m | \u001b[0m0.4747   \u001b[0m | \u001b[0m84.48    \u001b[0m | \u001b[0m0.2833   \u001b[0m | \u001b[0m0.9609   \u001b[0m |\n",
            "=============================================================================================================================================================\n"
          ]
        }
      ],
      "source": [
        "params_nn1 ={\n",
        "    'neurons': (10, 100),\n",
        "    'activation':(0.01, 1),\n",
        "    'optimizer':(0,1),\n",
        "    'learning_rate':(0.01, 1),\n",
        "    'batch_size':(200, 1000),\n",
        "    'epochs':(20, 100),\n",
        "    'layers1':(1,5),\n",
        "    'layers2':(1,5),\n",
        "    'normalization':(0,1),\n",
        "    'dropout':(0,1),\n",
        "    'dropout_rate':(0,0.3)\n",
        "}\n",
        "# Run Bayesian Optimization\n",
        "nn_bo1 = BayesianOptimization(function1, params_nn1, random_state=2023)\n",
        "nn_bo1.maximize(init_points=25, n_iter=4)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "015bc49a",
      "metadata": {
        "id": "015bc49a"
      },
      "source": [
        "**BEST PARAMS**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "59ce0466",
      "metadata": {
        "id": "59ce0466",
        "outputId": "34b39a51-31e2-40e9-982a-cb8b5a557559"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'activation': 'relu',\n",
              " 'batch_size': 501,\n",
              " 'dropout': 0.1840541418275664,\n",
              " 'dropout_rate': 0.031185550905878476,\n",
              " 'epochs': 56,\n",
              " 'layers1': 2,\n",
              " 'layers2': 3,\n",
              " 'learning_rate': 0.931226639688736,\n",
              " 'neurons': 78,\n",
              " 'normalization': 0.7707642376587938,\n",
              " 'optimizer': <keras.optimizers.legacy.adam.Adam at 0x12183e51220>}"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "params_nn_ = nn_bo1.max['params']\n",
        "learning_rate = params_nn_['learning_rate']\n",
        "activationL = ['relu', 'relu']\n",
        "params_nn_['activation'] = activationL[round(params_nn_['activation'])]\n",
        "params_nn_['batch_size'] = round(params_nn_['batch_size'])\n",
        "params_nn_['epochs'] = round(params_nn_['epochs'])\n",
        "params_nn_['layers1'] = round(params_nn_['layers1'])\n",
        "params_nn_['layers2'] = round(params_nn_['layers2'])\n",
        "params_nn_['neurons'] = round(params_nn_['neurons'])\n",
        "optimizerL = ['Adam', 'Adam']\n",
        "optimizerD= {'Adam':Adam(lr=learning_rate)}\n",
        "params_nn_['optimizer'] = optimizerD[optimizerL[round(params_nn_['optimizer'])]]\n",
        "params_nn_"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "252de898",
      "metadata": {
        "id": "252de898"
      },
      "source": [
        "**MODEL**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "34822ff3",
      "metadata": {
        "scrolled": true,
        "id": "34822ff3",
        "outputId": "a1459e48-9b84-400a-db6c-2c5d8ae80331"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/56\n",
            "38/38 [==============================] - 1s 3ms/step - loss: 23868704030720.0000 - mse: 23868704030720.0000\n",
            "Epoch 2/56\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 23854827175936.0000 - mse: 23854827175936.0000\n",
            "Epoch 3/56\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 23412265189376.0000 - mse: 23412265189376.0000\n",
            "Epoch 4/56\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 20446705614848.0000 - mse: 20446705614848.0000\n",
            "Epoch 5/56\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 15679864438784.0000 - mse: 15679864438784.0000\n",
            "Epoch 6/56\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 12874545102848.0000 - mse: 12874545102848.0000\n",
            "Epoch 7/56\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 10079893979136.0000 - mse: 10079893979136.0000\n",
            "Epoch 8/56\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 7363148906496.0000 - mse: 7363148906496.0000\n",
            "Epoch 9/56\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 5935056551936.0000 - mse: 5935056551936.0000\n",
            "Epoch 10/56\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 4267242422272.0000 - mse: 4267242422272.0000\n",
            "Epoch 11/56\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 3289957531648.0000 - mse: 3289957531648.0000\n",
            "Epoch 12/56\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 4232415019008.0000 - mse: 4232415019008.0000\n",
            "Epoch 13/56\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 3435063148544.0000 - mse: 3435063148544.0000\n",
            "Epoch 14/56\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 2890463969280.0000 - mse: 2890463969280.0000\n",
            "Epoch 15/56\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 3313863753728.0000 - mse: 3313863753728.0000\n",
            "Epoch 16/56\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 3596571377664.0000 - mse: 3596571377664.0000\n",
            "Epoch 17/56\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 4986215333888.0000 - mse: 4986215333888.0000\n",
            "Epoch 18/56\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 4047545827328.0000 - mse: 4047545827328.0000\n",
            "Epoch 19/56\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 4377880821760.0000 - mse: 4377880821760.0000\n",
            "Epoch 20/56\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 2726485557248.0000 - mse: 2726485557248.0000\n",
            "Epoch 21/56\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 2654833999872.0000 - mse: 2654833999872.0000\n",
            "Epoch 22/56\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 2531009495040.0000 - mse: 2531009495040.0000\n",
            "Epoch 23/56\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 2783484837888.0000 - mse: 2783484837888.0000\n",
            "Epoch 24/56\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 2819775791104.0000 - mse: 2819775791104.0000\n",
            "Epoch 25/56\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 2239311904768.0000 - mse: 2239311904768.0000\n",
            "Epoch 26/56\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 3959691673600.0000 - mse: 3959691673600.0000\n",
            "Epoch 27/56\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 2337742782464.0000 - mse: 2337742782464.0000\n",
            "Epoch 28/56\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 2091671224320.0000 - mse: 2091671224320.0000\n",
            "Epoch 29/56\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 2141996318720.0000 - mse: 2141996318720.0000\n",
            "Epoch 30/56\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 2034648481792.0000 - mse: 2034648481792.0000\n",
            "Epoch 31/56\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 2540152553472.0000 - mse: 2540152553472.0000\n",
            "Epoch 32/56\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 1958026936320.0000 - mse: 1958026936320.0000\n",
            "Epoch 33/56\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 2376773140480.0000 - mse: 2376773140480.0000\n",
            "Epoch 34/56\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 2962115788800.0000 - mse: 2962115788800.0000\n",
            "Epoch 35/56\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 2330452033536.0000 - mse: 2330452033536.0000\n",
            "Epoch 36/56\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 2440443461632.0000 - mse: 2440443461632.0000\n",
            "Epoch 37/56\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 2555674099712.0000 - mse: 2555674099712.0000\n",
            "Epoch 38/56\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 1793235091456.0000 - mse: 1793235091456.0000\n",
            "Epoch 39/56\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 2037864333312.0000 - mse: 2037864333312.0000\n",
            "Epoch 40/56\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 1832159936512.0000 - mse: 1832159936512.0000\n",
            "Epoch 41/56\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 3717307039744.0000 - mse: 3717307039744.0000\n",
            "Epoch 42/56\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 1714703171584.0000 - mse: 1714703171584.0000\n",
            "Epoch 43/56\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 1734517456896.0000 - mse: 1734517456896.0000\n",
            "Epoch 44/56\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 1949247471616.0000 - mse: 1949247471616.0000\n",
            "Epoch 45/56\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 1558151299072.0000 - mse: 1558151299072.0000\n",
            "Epoch 46/56\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 1981644275712.0000 - mse: 1981644275712.0000\n",
            "Epoch 47/56\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 1708683952128.0000 - mse: 1708683952128.0000\n",
            "Epoch 48/56\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 3574517202944.0000 - mse: 3574517202944.0000\n",
            "Epoch 49/56\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 1675585781760.0000 - mse: 1675585781760.0000\n",
            "Epoch 50/56\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 1705978757120.0000 - mse: 1705978757120.0000\n",
            "Epoch 51/56\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 1641755574272.0000 - mse: 1641755574272.0000\n",
            "Epoch 52/56\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 1570690039808.0000 - mse: 1570690039808.0000\n",
            "Epoch 53/56\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 1309234036736.0000 - mse: 1309234036736.0000\n",
            "Epoch 54/56\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 1514466836480.0000 - mse: 1514466836480.0000\n",
            "Epoch 55/56\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 3081935781888.0000 - mse: 3081935781888.0000\n",
            "Epoch 56/56\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 1389043515392.0000 - mse: 1389043515392.0000\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x121809cf160>"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_1 = Sequential()\n",
        "model_1.add(Dense(params_nn_['neurons'], input_dim=74, activation=params_nn_['activation']))\n",
        "if params_nn_['normalization'] > 0.5:\n",
        "    model_1.add(BatchNormalization())\n",
        "for i in range(params_nn_['layers1']):\n",
        "    model_1.add(Dense(params_nn_['neurons'], activation=params_nn_['activation']))\n",
        "if params_nn_['dropout'] > 0.5:\n",
        "    model_1.add(Dropout(params_nn_['dropout_rate'], seed=2023))\n",
        "for i in range(params_nn_['layers2']):\n",
        "    model_1.add(Dense(params_nn_['neurons'], activation=params_nn_['activation']))\n",
        "model_1.add(Dense(1))\n",
        "model_1.compile(loss='mse', optimizer='adam', metrics=['mse'])\n",
        "    \n",
        "model_1.fit(X_train, y_train, epochs=params_nn_['epochs'], batch_size=params_nn_['batch_size'],verbose=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7cdba9ec",
      "metadata": {
        "id": "7cdba9ec"
      },
      "source": [
        "**EVALUATION**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f16d5c7",
      "metadata": {
        "id": "4f16d5c7",
        "outputId": "d1762a5b-dd60-44a0-9c4c-3b3948166965"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "149/149 [==============================] - 0s 473us/step\n",
            "Standard Deviation: price    5.275527e+06\n",
            "dtype: float64\n",
            "Range: price    342535000\n",
            "dtype: int64\n",
            "Mean squared error: 594849691614.395\n",
            "Mean absolute error: 554803.5541750158\n",
            "RMSE: 771264.9944178687\n",
            "R-squared: 0.9786219984129205\n",
            "Percentage of error compared to SD: price    10.516552\n",
            "dtype: float64\n"
          ]
        }
      ],
      "source": [
        "# For Non-scaled training data\n",
        "predicted_prices = model_1.predict(X_test)\n",
        "mse = mean_squared_error(y_test, predicted_prices)\n",
        "\n",
        "rmse = mean_squared_error(y_test, predicted_prices, squared=False)\n",
        "\n",
        "# Calculate mean absolute error\n",
        "mae = mean_absolute_error(y_test, predicted_prices)\n",
        "\n",
        "# Calculate coefficient of determination (R-squared)\n",
        "r2 = r2_score(y_test, predicted_prices)\n",
        "\n",
        "print('Standard Deviation:', y_test.std())\n",
        "print('Range:', y_test.max() - y_test.min())\n",
        "print('Mean squared error:', mse)\n",
        "print('Mean absolute error:', mae)\n",
        "print('RMSE:', rmse)\n",
        "print('R-squared:', r2)\n",
        "print('Percentage of error compared to SD:', mae/y_test.std() * 100)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a96ecf6e",
      "metadata": {
        "id": "a96ecf6e"
      },
      "source": [
        "# **With SCALED training data**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "23a487b6",
      "metadata": {
        "id": "23a487b6"
      },
      "source": [
        "**Hyperparameter Tuning**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a46dcbda",
      "metadata": {
        "id": "a46dcbda"
      },
      "outputs": [],
      "source": [
        "def function2(neurons, activation, optimizer, learning_rate, batch_size, epochs,\n",
        "              layers1, layers2, normalization, dropout, dropout_rate):\n",
        "    optimizerL = ['Adam', 'Adam'] #Fixing optimizer to Adam\n",
        "    optimizerD= {'Adam':Adam(lr=learning_rate)}\n",
        "    activationL = ['relu', 'relu'] #Fixing activation to relu\n",
        "    neurons = round(neurons)\n",
        "    activation = activationL[round(activation)]\n",
        "    optimizer = optimizerD[optimizerL[round(optimizer)]]\n",
        "    batch_size = round(batch_size)\n",
        "    epochs = round(epochs)\n",
        "    layers1 = round(layers1)\n",
        "    layers2 = round(layers2)\n",
        "    def nn_cl_fun():\n",
        "        nn = Sequential()\n",
        "        nn.add(Dense(neurons, input_dim=74, activation=activation))\n",
        "        if normalization > 0.5:\n",
        "            nn.add(BatchNormalization())\n",
        "        for i in range(layers1):\n",
        "            nn.add(Dense(neurons, activation=activation))\n",
        "        if dropout > 0.5:\n",
        "            nn.add(Dropout(dropout_rate, seed=2023))\n",
        "        for i in range(layers2):\n",
        "            nn.add(Dense(neurons, activation=activation))\n",
        "        nn.add(Dense(1))\n",
        "        nn.compile(loss='mse', optimizer=optimizer, metrics=['mse'])\n",
        "        return nn\n",
        "    es = EarlyStopping(monitor='mse', mode='min', verbose=0, patience=20)\n",
        "    nn = KerasClassifier(build_fn=nn_cl_fun, epochs=epochs, batch_size=batch_size, verbose=0)\n",
        "    kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=2023)\n",
        "    score = cross_val_score(nn, X_train_scaled, y_train, scoring=score_acc, cv=kfold, fit_params={'callbacks':[es]}).mean()\n",
        "    return score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "00a44dfc",
      "metadata": {
        "scrolled": true,
        "id": "00a44dfc",
        "outputId": "304edebc-0f7d-456e-9546-e627174cc344"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "|   iter    |  target   | activa... | batch_... |  dropout  | dropou... |  epochs   |  layers1  |  layers2  | learni... |  neurons  | normal... | optimizer |\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "119/119 [==============================] - 0s 450us/step\n",
            "119/119 [==============================] - 0s 458us/step\n",
            "119/119 [==============================] - 0s 458us/step\n",
            "119/119 [==============================] - 0s 467us/step\n",
            "119/119 [==============================] - 0s 467us/step\n",
            "| \u001b[0m1        \u001b[0m | \u001b[0m2.222e+13\u001b[0m | \u001b[0m0.3288   \u001b[0m | \u001b[0m912.3    \u001b[0m | \u001b[0m0.5881   \u001b[0m | \u001b[0m0.03798  \u001b[0m | \u001b[0m31.31    \u001b[0m | \u001b[0m2.872    \u001b[0m | \u001b[0m1.088    \u001b[0m | \u001b[0m0.73     \u001b[0m | \u001b[0m57.19    \u001b[0m | \u001b[0m0.5449   \u001b[0m | \u001b[0m0.4564   \u001b[0m |\n",
            "119/119 [==============================] - 0s 454us/step\n",
            "119/119 [==============================] - 0s 433us/step\n",
            "119/119 [==============================] - 0s 458us/step\n",
            "119/119 [==============================] - 0s 467us/step\n",
            "119/119 [==============================] - 0s 458us/step\n",
            "| \u001b[0m2        \u001b[0m | \u001b[0m2.22e+13 \u001b[0m | \u001b[0m0.5064   \u001b[0m | \u001b[0m515.6    \u001b[0m | \u001b[0m0.1512   \u001b[0m | \u001b[0m0.1083   \u001b[0m | \u001b[0m32.97    \u001b[0m | \u001b[0m2.352    \u001b[0m | \u001b[0m1.721    \u001b[0m | \u001b[0m0.3971   \u001b[0m | \u001b[0m13.21    \u001b[0m | \u001b[0m0.5649   \u001b[0m | \u001b[0m0.2035   \u001b[0m |\n",
            "119/119 [==============================] - 0s 492us/step\n",
            "119/119 [==============================] - 0s 464us/step\n",
            "119/119 [==============================] - 0s 488us/step\n",
            "119/119 [==============================] - 0s 475us/step\n",
            "119/119 [==============================] - 0s 475us/step\n",
            "| \u001b[95m3        \u001b[0m | \u001b[95m2.224e+13\u001b[0m | \u001b[95m0.3274   \u001b[0m | \u001b[95m501.3    \u001b[0m | \u001b[95m0.1841   \u001b[0m | \u001b[95m0.03119  \u001b[0m | \u001b[95m56.39    \u001b[0m | \u001b[95m1.783    \u001b[0m | \u001b[95m2.514    \u001b[0m | \u001b[95m0.9312   \u001b[0m | \u001b[95m78.41    \u001b[0m | \u001b[95m0.7708   \u001b[0m | \u001b[95m0.5967   \u001b[0m |\n",
            "119/119 [==============================] - 0s 475us/step\n",
            "119/119 [==============================] - 0s 458us/step\n",
            "119/119 [==============================] - 0s 500us/step\n",
            "119/119 [==============================] - 0s 467us/step\n",
            "119/119 [==============================] - 0s 500us/step\n",
            "| \u001b[0m4        \u001b[0m | \u001b[0m2.224e+13\u001b[0m | \u001b[0m0.7937   \u001b[0m | \u001b[0m848.3    \u001b[0m | \u001b[0m0.9806   \u001b[0m | \u001b[0m0.2654   \u001b[0m | \u001b[0m28.78    \u001b[0m | \u001b[0m4.279    \u001b[0m | \u001b[0m2.23     \u001b[0m | \u001b[0m0.2689   \u001b[0m | \u001b[0m46.52    \u001b[0m | \u001b[0m0.5534   \u001b[0m | \u001b[0m0.6255   \u001b[0m |\n",
            "119/119 [==============================] - 0s 458us/step\n",
            "119/119 [==============================] - 0s 467us/step\n",
            "119/119 [==============================] - 0s 467us/step\n",
            "119/119 [==============================] - 0s 450us/step\n",
            "119/119 [==============================] - 0s 475us/step\n",
            "| \u001b[0m5        \u001b[0m | \u001b[0m2.223e+13\u001b[0m | \u001b[0m0.08797  \u001b[0m | \u001b[0m977.8    \u001b[0m | \u001b[0m0.4113   \u001b[0m | \u001b[0m0.2165   \u001b[0m | \u001b[0m73.06    \u001b[0m | \u001b[0m1.873    \u001b[0m | \u001b[0m1.749    \u001b[0m | \u001b[0m0.7325   \u001b[0m | \u001b[0m87.7     \u001b[0m | \u001b[0m0.3917   \u001b[0m | \u001b[0m0.11     \u001b[0m |\n",
            "119/119 [==============================] - 0s 526us/step\n",
            "119/119 [==============================] - 0s 500us/step\n",
            "119/119 [==============================] - 0s 500us/step\n",
            "119/119 [==============================] - 0s 539us/step\n",
            "119/119 [==============================] - 0s 534us/step\n",
            "| \u001b[0m6        \u001b[0m | \u001b[0m2.223e+13\u001b[0m | \u001b[0m0.9137   \u001b[0m | \u001b[0m485.6    \u001b[0m | \u001b[0m0.413    \u001b[0m | \u001b[0m0.05506  \u001b[0m | \u001b[0m66.88    \u001b[0m | \u001b[0m4.423    \u001b[0m | \u001b[0m4.159    \u001b[0m | \u001b[0m0.09696  \u001b[0m | \u001b[0m93.97    \u001b[0m | \u001b[0m0.5      \u001b[0m | \u001b[0m0.3643   \u001b[0m |\n",
            "119/119 [==============================] - 0s 450us/step\n",
            "119/119 [==============================] - 0s 450us/step\n",
            "119/119 [==============================] - 0s 467us/step\n",
            "119/119 [==============================] - 0s 450us/step\n",
            "119/119 [==============================] - 0s 458us/step\n",
            "| \u001b[0m7        \u001b[0m | \u001b[0m2.22e+13 \u001b[0m | \u001b[0m0.4888   \u001b[0m | \u001b[0m612.2    \u001b[0m | \u001b[0m0.9946   \u001b[0m | \u001b[0m0.226    \u001b[0m | \u001b[0m49.27    \u001b[0m | \u001b[0m3.445    \u001b[0m | \u001b[0m2.678    \u001b[0m | \u001b[0m0.1008   \u001b[0m | \u001b[0m58.14    \u001b[0m | \u001b[0m0.3408   \u001b[0m | \u001b[0m0.01834  \u001b[0m |\n",
            "119/119 [==============================] - 0s 458us/step\n",
            "119/119 [==============================] - 0s 458us/step\n",
            "119/119 [==============================] - 0s 437us/step\n",
            "119/119 [==============================] - 0s 450us/step\n",
            "119/119 [==============================] - 0s 416us/step\n",
            "| \u001b[0m8        \u001b[0m | \u001b[0m2.22e+13 \u001b[0m | \u001b[0m0.6074   \u001b[0m | \u001b[0m937.4    \u001b[0m | \u001b[0m0.2814   \u001b[0m | \u001b[0m0.2504   \u001b[0m | \u001b[0m63.97    \u001b[0m | \u001b[0m1.087    \u001b[0m | \u001b[0m2.388    \u001b[0m | \u001b[0m0.5545   \u001b[0m | \u001b[0m11.19    \u001b[0m | \u001b[0m0.7159   \u001b[0m | \u001b[0m0.1898   \u001b[0m |\n",
            "119/119 [==============================] - 0s 500us/step\n",
            "119/119 [==============================] - 0s 492us/step\n",
            "119/119 [==============================] - 0s 492us/step\n",
            "119/119 [==============================] - 0s 526us/step\n",
            "119/119 [==============================] - 0s 500us/step\n",
            "| \u001b[0m9        \u001b[0m | \u001b[0m2.224e+13\u001b[0m | \u001b[0m0.745    \u001b[0m | \u001b[0m703.5    \u001b[0m | \u001b[0m0.3622   \u001b[0m | \u001b[0m0.1881   \u001b[0m | \u001b[0m61.19    \u001b[0m | \u001b[0m4.58     \u001b[0m | \u001b[0m3.075    \u001b[0m | \u001b[0m0.6113   \u001b[0m | \u001b[0m52.73    \u001b[0m | \u001b[0m0.7096   \u001b[0m | \u001b[0m0.1152   \u001b[0m |\n",
            "119/119 [==============================] - 0s 458us/step\n",
            "119/119 [==============================] - 0s 458us/step\n",
            "119/119 [==============================] - 0s 498us/step\n",
            "119/119 [==============================] - 0s 458us/step\n",
            "119/119 [==============================] - 0s 458us/step\n",
            "| \u001b[0m10       \u001b[0m | \u001b[0m2.224e+13\u001b[0m | \u001b[0m0.7355   \u001b[0m | \u001b[0m902.4    \u001b[0m | \u001b[0m0.5191   \u001b[0m | \u001b[0m0.2041   \u001b[0m | \u001b[0m54.84    \u001b[0m | \u001b[0m4.887    \u001b[0m | \u001b[0m2.461    \u001b[0m | \u001b[0m0.6265   \u001b[0m | \u001b[0m33.25    \u001b[0m | \u001b[0m0.6813   \u001b[0m | \u001b[0m0.8766   \u001b[0m |\n",
            "119/119 [==============================] - 0s 440us/step\n",
            "119/119 [==============================] - 0s 450us/step\n",
            "119/119 [==============================] - 0s 441us/step\n",
            "119/119 [==============================] - 0s 458us/step\n",
            "119/119 [==============================] - 0s 450us/step\n",
            "| \u001b[0m11       \u001b[0m | \u001b[0m2.224e+13\u001b[0m | \u001b[0m0.2498   \u001b[0m | \u001b[0m314.1    \u001b[0m | \u001b[0m0.8254   \u001b[0m | \u001b[0m0.1396   \u001b[0m | \u001b[0m47.05    \u001b[0m | \u001b[0m4.735    \u001b[0m | \u001b[0m2.818    \u001b[0m | \u001b[0m0.4993   \u001b[0m | \u001b[0m14.13    \u001b[0m | \u001b[0m0.119    \u001b[0m | \u001b[0m0.538    \u001b[0m |\n",
            "119/119 [==============================] - 0s 492us/step\n",
            "119/119 [==============================] - 0s 483us/step\n",
            "119/119 [==============================] - 0s 492us/step\n",
            "119/119 [==============================] - 0s 500us/step\n",
            "119/119 [==============================] - 0s 500us/step\n",
            "| \u001b[0m12       \u001b[0m | \u001b[0m2.221e+13\u001b[0m | \u001b[0m0.06424  \u001b[0m | \u001b[0m440.4    \u001b[0m | \u001b[0m0.3781   \u001b[0m | \u001b[0m0.1827   \u001b[0m | \u001b[0m85.91    \u001b[0m | \u001b[0m1.732    \u001b[0m | \u001b[0m4.148    \u001b[0m | \u001b[0m0.3183   \u001b[0m | \u001b[0m79.44    \u001b[0m | \u001b[0m0.9149   \u001b[0m | \u001b[0m0.2263   \u001b[0m |\n",
            "119/119 [==============================] - 0s 526us/step\n",
            "119/119 [==============================] - 0s 509us/step\n",
            "119/119 [==============================] - 0s 483us/step\n",
            "119/119 [==============================] - 0s 488us/step\n",
            "119/119 [==============================] - 0s 509us/step\n",
            "| \u001b[0m13       \u001b[0m | \u001b[0m2.224e+13\u001b[0m | \u001b[0m0.9912   \u001b[0m | \u001b[0m449.2    \u001b[0m | \u001b[0m0.8856   \u001b[0m | \u001b[0m0.2081   \u001b[0m | \u001b[0m24.36    \u001b[0m | \u001b[0m1.807    \u001b[0m | \u001b[0m4.437    \u001b[0m | \u001b[0m0.6641   \u001b[0m | \u001b[0m88.55    \u001b[0m | \u001b[0m0.7237   \u001b[0m | \u001b[0m0.09194  \u001b[0m |\n",
            "119/119 [==============================] - 0s 441us/step\n",
            "119/119 [==============================] - 0s 416us/step\n",
            "119/119 [==============================] - 0s 467us/step\n",
            "119/119 [==============================] - 0s 433us/step\n",
            "119/119 [==============================] - 0s 433us/step\n",
            "| \u001b[0m14       \u001b[0m | \u001b[0m2.22e+13 \u001b[0m | \u001b[0m0.03175  \u001b[0m | \u001b[0m345.6    \u001b[0m | \u001b[0m0.2761   \u001b[0m | \u001b[0m0.202    \u001b[0m | \u001b[0m65.64    \u001b[0m | \u001b[0m2.509    \u001b[0m | \u001b[0m2.138    \u001b[0m | \u001b[0m0.2106   \u001b[0m | \u001b[0m39.78    \u001b[0m | \u001b[0m0.3645   \u001b[0m | \u001b[0m0.2026   \u001b[0m |\n",
            "119/119 [==============================] - 0s 513us/step\n",
            "119/119 [==============================] - 0s 500us/step\n",
            "119/119 [==============================] - 0s 509us/step\n",
            "119/119 [==============================] - 0s 500us/step\n",
            "119/119 [==============================] - 0s 492us/step\n",
            "| \u001b[95m15       \u001b[0m | \u001b[95m2.224e+13\u001b[0m | \u001b[95m0.6069   \u001b[0m | \u001b[95m250.4    \u001b[0m | \u001b[95m0.7315   \u001b[0m | \u001b[95m0.2202   \u001b[0m | \u001b[95m67.21    \u001b[0m | \u001b[95m3.868    \u001b[0m | \u001b[95m3.853    \u001b[0m | \u001b[95m0.7781   \u001b[0m | \u001b[95m71.56    \u001b[0m | \u001b[95m0.7979   \u001b[0m | \u001b[95m0.589    \u001b[0m |\n",
            "119/119 [==============================] - 0s 441us/step\n",
            "119/119 [==============================] - 0s 458us/step\n",
            "119/119 [==============================] - 0s 467us/step\n",
            "119/119 [==============================] - 0s 458us/step\n",
            "119/119 [==============================] - 0s 483us/step\n",
            "| \u001b[0m16       \u001b[0m | \u001b[0m2.223e+13\u001b[0m | \u001b[0m0.8611   \u001b[0m | \u001b[0m553.8    \u001b[0m | \u001b[0m0.388    \u001b[0m | \u001b[0m0.08434  \u001b[0m | \u001b[0m27.63    \u001b[0m | \u001b[0m2.734    \u001b[0m | \u001b[0m3.705    \u001b[0m | \u001b[0m0.2582   \u001b[0m | \u001b[0m40.57    \u001b[0m | \u001b[0m0.6354   \u001b[0m | \u001b[0m0.681    \u001b[0m |\n",
            "119/119 [==============================] - 0s 551us/step\n",
            "119/119 [==============================] - 0s 526us/step\n",
            "119/119 [==============================] - 0s 526us/step\n",
            "119/119 [==============================] - 0s 517us/step\n",
            "119/119 [==============================] - 0s 523us/step\n",
            "| \u001b[0m17       \u001b[0m | \u001b[0m2.224e+13\u001b[0m | \u001b[0m0.3567   \u001b[0m | \u001b[0m604.8    \u001b[0m | \u001b[0m0.4119   \u001b[0m | \u001b[0m0.2227   \u001b[0m | \u001b[0m31.6     \u001b[0m | \u001b[0m3.925    \u001b[0m | \u001b[0m3.062    \u001b[0m | \u001b[0m0.3393   \u001b[0m | \u001b[0m93.31    \u001b[0m | \u001b[0m0.9734   \u001b[0m | \u001b[0m0.5595   \u001b[0m |\n",
            "119/119 [==============================] - 0s 551us/step\n",
            "119/119 [==============================] - 0s 534us/step\n",
            "119/119 [==============================] - 0s 543us/step\n",
            "119/119 [==============================] - 0s 560us/step\n",
            "119/119 [==============================] - 0s 553us/step\n",
            "| \u001b[0m18       \u001b[0m | \u001b[0m2.224e+13\u001b[0m | \u001b[0m0.1109   \u001b[0m | \u001b[0m737.7    \u001b[0m | \u001b[0m0.9307   \u001b[0m | \u001b[0m0.08556  \u001b[0m | \u001b[0m29.43    \u001b[0m | \u001b[0m4.402    \u001b[0m | \u001b[0m3.782    \u001b[0m | \u001b[0m0.9006   \u001b[0m | \u001b[0m94.77    \u001b[0m | \u001b[0m0.5163   \u001b[0m | \u001b[0m0.6949   \u001b[0m |\n",
            "119/119 [==============================] - 0s 441us/step\n",
            "119/119 [==============================] - 0s 450us/step\n",
            "119/119 [==============================] - 0s 450us/step\n",
            "119/119 [==============================] - 0s 441us/step\n",
            "119/119 [==============================] - 0s 450us/step\n",
            "| \u001b[0m19       \u001b[0m | \u001b[0m2.22e+13 \u001b[0m | \u001b[0m0.4372   \u001b[0m | \u001b[0m899.2    \u001b[0m | \u001b[0m0.6551   \u001b[0m | \u001b[0m0.02753  \u001b[0m | \u001b[0m43.47    \u001b[0m | \u001b[0m2.187    \u001b[0m | \u001b[0m2.334    \u001b[0m | \u001b[0m0.1267   \u001b[0m | \u001b[0m63.06    \u001b[0m | \u001b[0m0.4873   \u001b[0m | \u001b[0m0.1037   \u001b[0m |\n",
            "119/119 [==============================] - 0s 473us/step\n",
            "119/119 [==============================] - 0s 441us/step\n",
            "119/119 [==============================] - 0s 450us/step\n",
            "119/119 [==============================] - 0s 450us/step\n",
            "119/119 [==============================] - 0s 446us/step\n",
            "| \u001b[0m20       \u001b[0m | \u001b[0m2.224e+13\u001b[0m | \u001b[0m0.3013   \u001b[0m | \u001b[0m701.7    \u001b[0m | \u001b[0m0.07346  \u001b[0m | \u001b[0m0.05054  \u001b[0m | \u001b[0m76.62    \u001b[0m | \u001b[0m3.378    \u001b[0m | \u001b[0m3.057    \u001b[0m | \u001b[0m0.54     \u001b[0m | \u001b[0m33.33    \u001b[0m | \u001b[0m0.6661   \u001b[0m | \u001b[0m0.02819  \u001b[0m |\n",
            "119/119 [==============================] - 0s 475us/step\n",
            "119/119 [==============================] - 0s 467us/step\n",
            "119/119 [==============================] - 0s 467us/step\n",
            "119/119 [==============================] - 0s 475us/step\n",
            "119/119 [==============================] - 0s 458us/step\n",
            "| \u001b[0m21       \u001b[0m | \u001b[0m2.224e+13\u001b[0m | \u001b[0m0.6874   \u001b[0m | \u001b[0m667.3    \u001b[0m | \u001b[0m0.5589   \u001b[0m | \u001b[0m0.04195  \u001b[0m | \u001b[0m30.23    \u001b[0m | \u001b[0m3.178    \u001b[0m | \u001b[0m3.264    \u001b[0m | \u001b[0m0.8174   \u001b[0m | \u001b[0m41.98    \u001b[0m | \u001b[0m0.5924   \u001b[0m | \u001b[0m0.6753   \u001b[0m |\n",
            "119/119 [==============================] - 0s 483us/step\n",
            "119/119 [==============================] - 0s 467us/step\n",
            "119/119 [==============================] - 0s 475us/step\n",
            "119/119 [==============================] - 0s 517us/step\n",
            "119/119 [==============================] - 0s 450us/step\n",
            "| \u001b[0m22       \u001b[0m | \u001b[0m2.224e+13\u001b[0m | \u001b[0m0.09972  \u001b[0m | \u001b[0m783.9    \u001b[0m | \u001b[0m0.7164   \u001b[0m | \u001b[0m0.2642   \u001b[0m | \u001b[0m53.48    \u001b[0m | \u001b[0m1.875    \u001b[0m | \u001b[0m3.743    \u001b[0m | \u001b[0m0.9643   \u001b[0m | \u001b[0m61.84    \u001b[0m | \u001b[0m0.2376   \u001b[0m | \u001b[0m0.3408   \u001b[0m |\n",
            "119/119 [==============================] - 0s 500us/step\n",
            "119/119 [==============================] - 0s 500us/step\n",
            "119/119 [==============================] - 0s 483us/step\n",
            "119/119 [==============================] - 0s 619us/step\n",
            "119/119 [==============================] - 0s 551us/step\n",
            "| \u001b[0m23       \u001b[0m | \u001b[0m2.224e+13\u001b[0m | \u001b[0m0.6347   \u001b[0m | \u001b[0m741.3    \u001b[0m | \u001b[0m0.6444   \u001b[0m | \u001b[0m0.201    \u001b[0m | \u001b[0m66.52    \u001b[0m | \u001b[0m2.763    \u001b[0m | \u001b[0m3.407    \u001b[0m | \u001b[0m0.3842   \u001b[0m | \u001b[0m33.18    \u001b[0m | \u001b[0m0.9529   \u001b[0m | \u001b[0m0.5877   \u001b[0m |\n",
            "119/119 [==============================] - 0s 645us/step\n",
            "119/119 [==============================] - 0s 526us/step\n",
            "119/119 [==============================] - 0s 509us/step\n",
            "119/119 [==============================] - 0s 509us/step\n",
            "119/119 [==============================] - 0s 483us/step\n",
            "| \u001b[0m24       \u001b[0m | \u001b[0m2.223e+13\u001b[0m | \u001b[0m0.826    \u001b[0m | \u001b[0m594.4    \u001b[0m | \u001b[0m0.681    \u001b[0m | \u001b[0m0.1518   \u001b[0m | \u001b[0m38.07    \u001b[0m | \u001b[0m2.38     \u001b[0m | \u001b[0m4.119    \u001b[0m | \u001b[0m0.1059   \u001b[0m | \u001b[0m83.26    \u001b[0m | \u001b[0m0.1024   \u001b[0m | \u001b[0m0.6199   \u001b[0m |\n",
            "119/119 [==============================] - 0s 446us/step\n",
            "119/119 [==============================] - 0s 440us/step\n",
            "119/119 [==============================] - 0s 458us/step\n",
            "119/119 [==============================] - 0s 433us/step\n",
            "119/119 [==============================] - 0s 458us/step\n",
            "| \u001b[0m25       \u001b[0m | \u001b[0m2.222e+13\u001b[0m | \u001b[0m0.08354  \u001b[0m | \u001b[0m976.4    \u001b[0m | \u001b[0m0.6527   \u001b[0m | \u001b[0m0.2858   \u001b[0m | \u001b[0m76.45    \u001b[0m | \u001b[0m1.421    \u001b[0m | \u001b[0m2.57     \u001b[0m | \u001b[0m0.7721   \u001b[0m | \u001b[0m61.96    \u001b[0m | \u001b[0m0.3429   \u001b[0m | \u001b[0m0.02441  \u001b[0m |\n",
            "119/119 [==============================] - 0s 441us/step\n",
            "119/119 [==============================] - 0s 450us/step\n",
            "119/119 [==============================] - 0s 441us/step\n",
            "119/119 [==============================] - 0s 441us/step\n",
            "119/119 [==============================] - 0s 450us/step\n",
            "| \u001b[0m26       \u001b[0m | \u001b[0m2.224e+13\u001b[0m | \u001b[0m0.6066   \u001b[0m | \u001b[0m719.3    \u001b[0m | \u001b[0m0.2728   \u001b[0m | \u001b[0m0.1498   \u001b[0m | \u001b[0m59.36    \u001b[0m | \u001b[0m3.091    \u001b[0m | \u001b[0m1.113    \u001b[0m | \u001b[0m0.8457   \u001b[0m | \u001b[0m36.88    \u001b[0m | \u001b[0m0.675    \u001b[0m | \u001b[0m0.8586   \u001b[0m |\n",
            "119/119 [==============================] - 0s 441us/step\n",
            "119/119 [==============================] - 0s 446us/step\n",
            "119/119 [==============================] - 0s 433us/step\n",
            "119/119 [==============================] - 0s 441us/step\n",
            "119/119 [==============================] - 0s 445us/step\n",
            "| \u001b[0m27       \u001b[0m | \u001b[0m2.224e+13\u001b[0m | \u001b[0m0.8391   \u001b[0m | \u001b[0m688.2    \u001b[0m | \u001b[0m0.8424   \u001b[0m | \u001b[0m0.07165  \u001b[0m | \u001b[0m43.4     \u001b[0m | \u001b[0m4.181    \u001b[0m | \u001b[0m3.308    \u001b[0m | \u001b[0m0.402    \u001b[0m | \u001b[0m35.04    \u001b[0m | \u001b[0m0.1756   \u001b[0m | \u001b[0m0.8718   \u001b[0m |\n",
            "119/119 [==============================] - 0s 458us/step\n",
            "119/119 [==============================] - 0s 467us/step\n",
            "119/119 [==============================] - 0s 458us/step\n",
            "119/119 [==============================] - 0s 483us/step\n",
            "119/119 [==============================] - 0s 467us/step\n",
            "| \u001b[0m28       \u001b[0m | \u001b[0m2.224e+13\u001b[0m | \u001b[0m0.2634   \u001b[0m | \u001b[0m749.8    \u001b[0m | \u001b[0m0.6821   \u001b[0m | \u001b[0m0.163    \u001b[0m | \u001b[0m49.74    \u001b[0m | \u001b[0m3.092    \u001b[0m | \u001b[0m3.523    \u001b[0m | \u001b[0m0.7636   \u001b[0m | \u001b[0m63.64    \u001b[0m | \u001b[0m0.5095   \u001b[0m | \u001b[0m0.4601   \u001b[0m |\n",
            "119/119 [==============================] - 0s 458us/step\n",
            "119/119 [==============================] - 0s 458us/step\n",
            "119/119 [==============================] - 0s 467us/step\n",
            "119/119 [==============================] - 0s 498us/step\n",
            "119/119 [==============================] - 0s 458us/step\n",
            "| \u001b[0m29       \u001b[0m | \u001b[0m2.224e+13\u001b[0m | \u001b[0m0.1549   \u001b[0m | \u001b[0m663.9    \u001b[0m | \u001b[0m0.4203   \u001b[0m | \u001b[0m0.2652   \u001b[0m | \u001b[0m28.76    \u001b[0m | \u001b[0m2.813    \u001b[0m | \u001b[0m3.277    \u001b[0m | \u001b[0m0.4453   \u001b[0m | \u001b[0m36.61    \u001b[0m | \u001b[0m0.8668   \u001b[0m | \u001b[0m0.1497   \u001b[0m |\n",
            "=============================================================================================================================================================\n"
          ]
        }
      ],
      "source": [
        "params_nn2 ={\n",
        "    'neurons': (10, 100),\n",
        "    'activation':(0.01, 1),\n",
        "    'optimizer':(0,1),\n",
        "    'learning_rate':(0.01, 1),\n",
        "    'batch_size':(200, 1000),\n",
        "    'epochs':(20, 100),\n",
        "    'layers1':(1,5),\n",
        "    'layers2':(1,5),\n",
        "    'normalization':(0,1),\n",
        "    'dropout':(0,1),\n",
        "    'dropout_rate':(0,0.3)\n",
        "}\n",
        "# Run Bayesian Optimization\n",
        "nn_bo2 = BayesianOptimization(function2, params_nn2, random_state=2023)\n",
        "nn_bo2.maximize(init_points=25, n_iter=4)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d0382153",
      "metadata": {
        "id": "d0382153"
      },
      "source": [
        "**BEST PARAMS**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8bcdc0ef",
      "metadata": {
        "id": "8bcdc0ef",
        "outputId": "f0b888b7-dcb4-415a-b07f-b9000408c28d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'activation': 'relu',\n",
              " 'batch_size': 250,\n",
              " 'dropout': 0.7314779358819499,\n",
              " 'dropout_rate': 0.22015325553707069,\n",
              " 'epochs': 67,\n",
              " 'layers1': 4,\n",
              " 'layers2': 4,\n",
              " 'learning_rate': 0.7781105957058365,\n",
              " 'neurons': 72,\n",
              " 'normalization': 0.7978975925046432,\n",
              " 'optimizer': <keras.optimizers.legacy.adam.Adam at 0x121fe925310>}"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "params_nn_2 = nn_bo2.max['params']\n",
        "learning_rate = params_nn_2['learning_rate']\n",
        "activationL = ['relu', 'relu']\n",
        "params_nn_2['activation'] = activationL[round(params_nn_2['activation'])]\n",
        "params_nn_2['batch_size'] = round(params_nn_2['batch_size'])\n",
        "params_nn_2['epochs'] = round(params_nn_2['epochs'])\n",
        "params_nn_2['layers1'] = round(params_nn_2['layers1'])\n",
        "params_nn_2['layers2'] = round(params_nn_2['layers2'])\n",
        "params_nn_2['neurons'] = round(params_nn_2['neurons'])\n",
        "optimizerL = ['Adam', 'Adam']\n",
        "optimizerD= {'Adam':Adam(lr=learning_rate)}\n",
        "params_nn_2['optimizer'] = optimizerD[optimizerL[round(params_nn_2['optimizer'])]]\n",
        "params_nn_2"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "07550746",
      "metadata": {
        "id": "07550746"
      },
      "source": [
        "**MODEL**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c7b9d3aa",
      "metadata": {
        "scrolled": true,
        "id": "c7b9d3aa",
        "outputId": "a48b6255-a6aa-4fa1-fe64-a09b52959003"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/67\n",
            "76/76 [==============================] - 1s 2ms/step - loss: 23287323164672.0000 - mse: 23287323164672.0000\n",
            "Epoch 2/67\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 16348929327104.0000 - mse: 16348929327104.0000\n",
            "Epoch 3/67\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 11145784066048.0000 - mse: 11145784066048.0000\n",
            "Epoch 4/67\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 5275342340096.0000 - mse: 5275342340096.0000\n",
            "Epoch 5/67\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 2685334716416.0000 - mse: 2685334716416.0000\n",
            "Epoch 6/67\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 6154985930752.0000 - mse: 6154985930752.0000\n",
            "Epoch 7/67\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 2540620742656.0000 - mse: 2540620742656.0000\n",
            "Epoch 8/67\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 2500815486976.0000 - mse: 2500815486976.0000\n",
            "Epoch 9/67\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 2793325461504.0000 - mse: 2793325461504.0000\n",
            "Epoch 10/67\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 4890597261312.0000 - mse: 4890597261312.0000\n",
            "Epoch 11/67\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 3046541885440.0000 - mse: 3046541885440.0000\n",
            "Epoch 12/67\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 2408881586176.0000 - mse: 2408881586176.0000\n",
            "Epoch 13/67\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 2891522244608.0000 - mse: 2891522244608.0000\n",
            "Epoch 14/67\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 4203376017408.0000 - mse: 4203376017408.0000\n",
            "Epoch 15/67\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 3674042269696.0000 - mse: 3674042269696.0000\n",
            "Epoch 16/67\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 2496219578368.0000 - mse: 2496219578368.0000\n",
            "Epoch 17/67\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 1633745633280.0000 - mse: 1633745633280.0000\n",
            "Epoch 18/67\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 2385046667264.0000 - mse: 2385046667264.0000\n",
            "Epoch 19/67\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 2229686239232.0000 - mse: 2229686239232.0000\n",
            "Epoch 20/67\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 2820101636096.0000 - mse: 2820101636096.0000\n",
            "Epoch 21/67\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 1413188157440.0000 - mse: 1413188157440.0000\n",
            "Epoch 22/67\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 1563023769600.0000 - mse: 1563023769600.0000\n",
            "Epoch 23/67\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 1382245859328.0000 - mse: 1382245859328.0000\n",
            "Epoch 24/67\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 2244298145792.0000 - mse: 2244298145792.0000\n",
            "Epoch 25/67\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 856962564096.0000 - mse: 856962564096.0000\n",
            "Epoch 26/67\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 2013095919616.0000 - mse: 2013095919616.0000\n",
            "Epoch 27/67\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 906217652224.0000 - mse: 906217652224.0000\n",
            "Epoch 28/67\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 507472117760.0000 - mse: 507472117760.0000\n",
            "Epoch 29/67\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 900207280128.0000 - mse: 900207280128.0000\n",
            "Epoch 30/67\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 595935952896.0000 - mse: 595935952896.0000\n",
            "Epoch 31/67\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 489296887808.0000 - mse: 489296887808.0000\n",
            "Epoch 32/67\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 823815897088.0000 - mse: 823815897088.0000\n",
            "Epoch 33/67\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 779690901504.0000 - mse: 779690901504.0000\n",
            "Epoch 34/67\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 1690759200768.0000 - mse: 1690759200768.0000\n",
            "Epoch 35/67\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 2523060764672.0000 - mse: 2523060764672.0000\n",
            "Epoch 36/67\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 707250552832.0000 - mse: 707250552832.0000\n",
            "Epoch 37/67\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 394768613376.0000 - mse: 394768613376.0000\n",
            "Epoch 38/67\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 447777570816.0000 - mse: 447777570816.0000\n",
            "Epoch 39/67\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 341717614592.0000 - mse: 341717614592.0000\n",
            "Epoch 40/67\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 651179655168.0000 - mse: 651179655168.0000\n",
            "Epoch 41/67\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 381254729728.0000 - mse: 381254729728.0000\n",
            "Epoch 42/67\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 359320190976.0000 - mse: 359320190976.0000\n",
            "Epoch 43/67\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 666198605824.0000 - mse: 666198605824.0000\n",
            "Epoch 44/67\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 824162975744.0000 - mse: 824162975744.0000\n",
            "Epoch 45/67\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 711756480512.0000 - mse: 711756480512.0000\n",
            "Epoch 46/67\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 575399788544.0000 - mse: 575399788544.0000\n",
            "Epoch 47/67\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 642878996480.0000 - mse: 642878996480.0000\n",
            "Epoch 48/67\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 1310816600064.0000 - mse: 1310816600064.0000\n",
            "Epoch 49/67\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 458804658176.0000 - mse: 458804658176.0000\n",
            "Epoch 50/67\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 625164681216.0000 - mse: 625164615680.0000\n",
            "Epoch 51/67\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 668925427712.0000 - mse: 668925427712.0000\n",
            "Epoch 52/67\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 632909004800.0000 - mse: 632909004800.0000\n",
            "Epoch 53/67\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 702959517696.0000 - mse: 702959517696.0000\n",
            "Epoch 54/67\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 400793698304.0000 - mse: 400793698304.0000\n",
            "Epoch 55/67\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 1220929519616.0000 - mse: 1220929519616.0000\n",
            "Epoch 56/67\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 1446262734848.0000 - mse: 1446262734848.0000\n",
            "Epoch 57/67\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 493324730368.0000 - mse: 493324730368.0000\n",
            "Epoch 58/67\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 483729965056.0000 - mse: 483729965056.0000\n",
            "Epoch 59/67\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 773811666944.0000 - mse: 773811666944.0000\n",
            "Epoch 60/67\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 586835361792.0000 - mse: 586835361792.0000\n",
            "Epoch 61/67\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 1120342114304.0000 - mse: 1120342114304.0000\n",
            "Epoch 62/67\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 4124780789760.0000 - mse: 4124780789760.0000\n",
            "Epoch 63/67\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 2490997407744.0000 - mse: 2490997407744.0000\n",
            "Epoch 64/67\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 541702291456.0000 - mse: 541702291456.0000\n",
            "Epoch 65/67\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 1436505735168.0000 - mse: 1436505735168.0000\n",
            "Epoch 66/67\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 1569274462208.0000 - mse: 1569274462208.0000\n",
            "Epoch 67/67\n",
            "76/76 [==============================] - 0s 2ms/step - loss: 618063331328.0000 - mse: 618063331328.0000\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x121802d8c70>"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_2 = Sequential()\n",
        "model_2.add(Dense(params_nn_2['neurons'], input_dim=74, activation=params_nn_2['activation']))\n",
        "if params_nn_2['normalization'] > 0.5:\n",
        "    model_2.add(BatchNormalization())\n",
        "for i in range(params_nn_2['layers1']):\n",
        "    model_2.add(Dense(params_nn_2['neurons'], activation=params_nn_2['activation']))\n",
        "if params_nn_2['dropout'] > 0.5:\n",
        "    model_2.add(Dropout(params_nn_2['dropout_rate'], seed=2023))\n",
        "for i in range(params_nn_2['layers2']):\n",
        "    model_2.add(Dense(params_nn_2['neurons'], activation=params_nn_2['activation']))\n",
        "model_2.add(Dense(1))\n",
        "model_2.compile(loss='mse', optimizer='adam', metrics=['mse'])\n",
        "\n",
        "model_2.fit(X_train_scaled, y_train, epochs=params_nn_2['epochs'], batch_size=params_nn_2['batch_size'], verbose=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "48192d88",
      "metadata": {
        "id": "48192d88"
      },
      "source": [
        "**EVALUATION**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "66c86b6d",
      "metadata": {
        "id": "66c86b6d",
        "outputId": "7017bff9-8fee-42f4-acba-ba778fd7478f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "149/149 [==============================] - 0s 500us/step\n",
            "Standard Deviation: price    5.275527e+06\n",
            "dtype: float64\n",
            "Range: price    342535000\n",
            "dtype: int64\n",
            "Mean squared error: 17739932846785.258\n",
            "Mean absolute error: 449198.51814622444\n",
            "RMSE: 4211879.965856726\n",
            "R-squared: 0.36245354431636856\n",
            "Percentage of error compared to SD: price    8.514761\n",
            "dtype: float64\n"
          ]
        }
      ],
      "source": [
        "# For Non-scaled training data\n",
        "predicted_prices2 = model_2.predict(X_test_scaled)\n",
        "mse2 = mean_squared_error(y_test, predicted_prices2)\n",
        "\n",
        "# Calculate mean absolute error\n",
        "mae2 = mean_absolute_error(y_test, predicted_prices2)\n",
        "\n",
        "rmse2 = mean_squared_error(y_test, predicted_prices2, squared=False)\n",
        "\n",
        "# Calculate coefficient of determination (R-squared)\n",
        "r2_2 = r2_score(y_test, predicted_prices2)\n",
        "\n",
        "print('Standard Deviation:', y_test.std())\n",
        "print('Range:', y_test.max() - y_test.min())\n",
        "print('Mean squared error:', mse2)\n",
        "print('Mean absolute error:', mae2)\n",
        "print('RMSE:', rmse2)\n",
        "print('R-squared:', r2_2)\n",
        "print('Percentage of error compared to SD:', mae2/y_test.std() * 100)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b1df79ee",
      "metadata": {
        "id": "b1df79ee"
      },
      "source": [
        "# With SelectKBest F Regression Training Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9e6ef309",
      "metadata": {
        "id": "9e6ef309",
        "outputId": "92a166e6-574b-4698-e398-7ee92b2e0f18"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10.0</td>\n",
              "      <td>53.0</td>\n",
              "      <td>0.209648</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>18.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>0.048992</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>0.209648</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6.0</td>\n",
              "      <td>141.0</td>\n",
              "      <td>0.197689</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11.0</td>\n",
              "      <td>85.0</td>\n",
              "      <td>0.182874</td>\n",
              "      <td>4.8</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18957</th>\n",
              "      <td>11.0</td>\n",
              "      <td>128.0</td>\n",
              "      <td>0.350559</td>\n",
              "      <td>4.8</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18958</th>\n",
              "      <td>19.0</td>\n",
              "      <td>46.0</td>\n",
              "      <td>0.066560</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18959</th>\n",
              "      <td>19.0</td>\n",
              "      <td>71.0</td>\n",
              "      <td>0.140742</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18960</th>\n",
              "      <td>17.0</td>\n",
              "      <td>63.0</td>\n",
              "      <td>0.087684</td>\n",
              "      <td>4.8</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18961</th>\n",
              "      <td>19.0</td>\n",
              "      <td>96.0</td>\n",
              "      <td>0.227100</td>\n",
              "      <td>4.1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>18962 rows × 21 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         0      1         2    3    4    5    6    7    8    9    10   11  \\\n",
              "0      10.0   53.0  0.209648  4.0  0.0  0.0  1.0  0.0  0.0  1.0  0.0  0.0   \n",
              "1      18.0   67.0  0.048992  4.0  1.0  0.0  1.0  0.0  0.0  1.0  0.0  0.0   \n",
              "2      10.0   87.0  0.209648  4.0  0.0  0.0  1.0  0.0  0.0  1.0  0.0  0.0   \n",
              "3       6.0  141.0  0.197689  4.0  1.0  0.0  1.0  0.0  0.0  1.0  0.0  0.0   \n",
              "4      11.0   85.0  0.182874  4.8  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0   \n",
              "...     ...    ...       ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
              "18957  11.0  128.0  0.350559  4.8  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0   \n",
              "18958  19.0   46.0  0.066560  4.0  0.0  1.0  0.0  0.0  0.0  1.0  0.0  1.0   \n",
              "18959  19.0   71.0  0.140742  4.0  0.0  1.0  1.0  0.0  0.0  1.0  0.0  1.0   \n",
              "18960  17.0   63.0  0.087684  4.8  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0   \n",
              "18961  19.0   96.0  0.227100  4.1  0.0  1.0  0.0  0.0  0.0  1.0  0.0  1.0   \n",
              "\n",
              "        12   13   14   15   16   17   18   19   20  \n",
              "0      0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  1.0  \n",
              "1      0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  \n",
              "2      0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  1.0  \n",
              "3      0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  \n",
              "4      0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
              "...    ...  ...  ...  ...  ...  ...  ...  ...  ...  \n",
              "18957  0.0  0.0  0.0  0.0  0.0  0.0  1.0  1.0  0.0  \n",
              "18958  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  1.0  \n",
              "18959  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  1.0  \n",
              "18960  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  \n",
              "18961  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  1.0  \n",
              "\n",
              "[18962 rows x 21 columns]"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train_f_reg_df = pd.DataFrame(X_train_f_reg_arr)\n",
        "X_train_f_reg_df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0159a59d",
      "metadata": {
        "id": "0159a59d"
      },
      "source": [
        "**Hyperparameter Tuning**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "071a93da",
      "metadata": {
        "id": "071a93da"
      },
      "outputs": [],
      "source": [
        "def function3(neurons, activation, optimizer, learning_rate, batch_size, epochs,\n",
        "              layers1, layers2, normalization, dropout, dropout_rate):\n",
        "    optimizerL = ['Adam', 'Adam'] #Fixing optimizer to Adam\n",
        "    optimizerD= {'Adam':Adam(lr=learning_rate)}\n",
        "    activationL = ['relu', 'relu'] #Fixing activation to relu\n",
        "    neurons = round(neurons)\n",
        "    activation = activationL[round(activation)]\n",
        "    optimizer = optimizerD[optimizerL[round(optimizer)]]\n",
        "    batch_size = round(batch_size)\n",
        "    epochs = round(epochs)\n",
        "    layers1 = round(layers1)\n",
        "    layers2 = round(layers2)\n",
        "    def nn_cl_fun():\n",
        "        nn = Sequential()\n",
        "        nn.add(Dense(neurons, input_dim=21, activation=activation))\n",
        "        if normalization > 0.5:\n",
        "            nn.add(BatchNormalization())\n",
        "        for i in range(layers1):\n",
        "            nn.add(Dense(neurons, activation=activation))\n",
        "        if dropout > 0.5:\n",
        "            nn.add(Dropout(dropout_rate, seed=2023))\n",
        "        for i in range(layers2):\n",
        "            nn.add(Dense(neurons, activation=activation))\n",
        "        nn.add(Dense(1))\n",
        "        nn.compile(loss='mse', optimizer=optimizer, metrics=['mse'])\n",
        "        return nn\n",
        "    es = EarlyStopping(monitor='mse', mode='min', verbose=0, patience=20)\n",
        "    nn = KerasClassifier(build_fn=nn_cl_fun, epochs=epochs, batch_size=batch_size, verbose=0)\n",
        "    kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=2023)\n",
        "    score = cross_val_score(nn, X_train_f_reg_df, y_train, scoring=score_acc, cv=kfold, fit_params={'callbacks':[es]}).mean()\n",
        "    return score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac11a53d",
      "metadata": {
        "scrolled": true,
        "id": "ac11a53d",
        "outputId": "01bbeb24-8d50-4f4b-bdf4-db20593df8e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "|   iter    |  target   | activa... | batch_... |  dropout  | dropou... |  epochs   |  layers1  |  layers2  | learni... |  neurons  | normal... | optimizer |\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "119/119 [==============================] - 0s 450us/step\n",
            "119/119 [==============================] - 0s 458us/step\n",
            "119/119 [==============================] - 0s 441us/step\n",
            "119/119 [==============================] - 0s 458us/step\n",
            "119/119 [==============================] - 0s 441us/step\n",
            "| \u001b[0m1        \u001b[0m | \u001b[0m2.224e+13\u001b[0m | \u001b[0m0.3288   \u001b[0m | \u001b[0m912.3    \u001b[0m | \u001b[0m0.5881   \u001b[0m | \u001b[0m0.03798  \u001b[0m | \u001b[0m31.31    \u001b[0m | \u001b[0m2.872    \u001b[0m | \u001b[0m1.088    \u001b[0m | \u001b[0m0.73     \u001b[0m | \u001b[0m57.19    \u001b[0m | \u001b[0m0.5449   \u001b[0m | \u001b[0m0.4564   \u001b[0m |\n",
            "119/119 [==============================] - 0s 450us/step\n",
            "119/119 [==============================] - 0s 450us/step\n",
            "119/119 [==============================] - 0s 458us/step\n",
            "119/119 [==============================] - 0s 441us/step\n",
            "119/119 [==============================] - 0s 441us/step\n",
            "| \u001b[0m2        \u001b[0m | \u001b[0m2.22e+13 \u001b[0m | \u001b[0m0.5064   \u001b[0m | \u001b[0m515.6    \u001b[0m | \u001b[0m0.1512   \u001b[0m | \u001b[0m0.1083   \u001b[0m | \u001b[0m32.97    \u001b[0m | \u001b[0m2.352    \u001b[0m | \u001b[0m1.721    \u001b[0m | \u001b[0m0.3971   \u001b[0m | \u001b[0m13.21    \u001b[0m | \u001b[0m0.5649   \u001b[0m | \u001b[0m0.2035   \u001b[0m |\n",
            "119/119 [==============================] - 0s 475us/step\n",
            "119/119 [==============================] - 0s 475us/step\n",
            "119/119 [==============================] - 0s 475us/step\n",
            "119/119 [==============================] - 0s 492us/step\n",
            "119/119 [==============================] - 0s 458us/step\n",
            "| \u001b[95m3        \u001b[0m | \u001b[95m2.224e+13\u001b[0m | \u001b[95m0.3274   \u001b[0m | \u001b[95m501.3    \u001b[0m | \u001b[95m0.1841   \u001b[0m | \u001b[95m0.03119  \u001b[0m | \u001b[95m56.39    \u001b[0m | \u001b[95m1.783    \u001b[0m | \u001b[95m2.514    \u001b[0m | \u001b[95m0.9312   \u001b[0m | \u001b[95m78.41    \u001b[0m | \u001b[95m0.7708   \u001b[0m | \u001b[95m0.5967   \u001b[0m |\n",
            "119/119 [==============================] - 0s 458us/step\n",
            "119/119 [==============================] - 0s 467us/step\n",
            "119/119 [==============================] - 0s 450us/step\n",
            "119/119 [==============================] - 0s 458us/step\n",
            "119/119 [==============================] - 0s 450us/step\n",
            "| \u001b[0m4        \u001b[0m | \u001b[0m2.22e+13 \u001b[0m | \u001b[0m0.7937   \u001b[0m | \u001b[0m848.3    \u001b[0m | \u001b[0m0.9806   \u001b[0m | \u001b[0m0.2654   \u001b[0m | \u001b[0m28.78    \u001b[0m | \u001b[0m4.279    \u001b[0m | \u001b[0m2.23     \u001b[0m | \u001b[0m0.2689   \u001b[0m | \u001b[0m46.52    \u001b[0m | \u001b[0m0.5534   \u001b[0m | \u001b[0m0.6255   \u001b[0m |\n",
            "119/119 [==============================] - 0s 458us/step\n",
            "119/119 [==============================] - 0s 458us/step\n",
            "119/119 [==============================] - 0s 458us/step\n",
            "119/119 [==============================] - 0s 458us/step\n",
            "119/119 [==============================] - 0s 441us/step\n",
            "| \u001b[0m5        \u001b[0m | \u001b[0m2.224e+13\u001b[0m | \u001b[0m0.08797  \u001b[0m | \u001b[0m977.8    \u001b[0m | \u001b[0m0.4113   \u001b[0m | \u001b[0m0.2165   \u001b[0m | \u001b[0m73.06    \u001b[0m | \u001b[0m1.873    \u001b[0m | \u001b[0m1.749    \u001b[0m | \u001b[0m0.7325   \u001b[0m | \u001b[0m87.7     \u001b[0m | \u001b[0m0.3917   \u001b[0m | \u001b[0m0.11     \u001b[0m |\n",
            "119/119 [==============================] - 0s 523us/step\n",
            "119/119 [==============================] - 0s 509us/step\n",
            "119/119 [==============================] - 0s 534us/step\n",
            "119/119 [==============================] - 0s 509us/step\n",
            "119/119 [==============================] - 0s 500us/step\n",
            "| \u001b[0m6        \u001b[0m | \u001b[0m2.223e+13\u001b[0m | \u001b[0m0.9137   \u001b[0m | \u001b[0m485.6    \u001b[0m | \u001b[0m0.413    \u001b[0m | \u001b[0m0.05506  \u001b[0m | \u001b[0m66.88    \u001b[0m | \u001b[0m4.423    \u001b[0m | \u001b[0m4.159    \u001b[0m | \u001b[0m0.09696  \u001b[0m | \u001b[0m93.97    \u001b[0m | \u001b[0m0.5      \u001b[0m | \u001b[0m0.3643   \u001b[0m |\n",
            "119/119 [==============================] - 0s 450us/step\n",
            "119/119 [==============================] - 0s 450us/step\n",
            "119/119 [==============================] - 0s 458us/step\n",
            "119/119 [==============================] - 0s 467us/step\n",
            "119/119 [==============================] - 0s 458us/step\n",
            "| \u001b[0m7        \u001b[0m | \u001b[0m2.223e+13\u001b[0m | \u001b[0m0.4888   \u001b[0m | \u001b[0m612.2    \u001b[0m | \u001b[0m0.9946   \u001b[0m | \u001b[0m0.226    \u001b[0m | \u001b[0m49.27    \u001b[0m | \u001b[0m3.445    \u001b[0m | \u001b[0m2.678    \u001b[0m | \u001b[0m0.1008   \u001b[0m | \u001b[0m58.14    \u001b[0m | \u001b[0m0.3408   \u001b[0m | \u001b[0m0.01834  \u001b[0m |\n",
            "119/119 [==============================] - 0s 433us/step\n",
            "119/119 [==============================] - 0s 441us/step\n",
            "119/119 [==============================] - 0s 441us/step\n",
            "119/119 [==============================] - 0s 441us/step\n",
            "119/119 [==============================] - 0s 450us/step\n",
            "| \u001b[0m8        \u001b[0m | \u001b[0m2.22e+13 \u001b[0m | \u001b[0m0.6074   \u001b[0m | \u001b[0m937.4    \u001b[0m | \u001b[0m0.2814   \u001b[0m | \u001b[0m0.2504   \u001b[0m | \u001b[0m63.97    \u001b[0m | \u001b[0m1.087    \u001b[0m | \u001b[0m2.388    \u001b[0m | \u001b[0m0.5545   \u001b[0m | \u001b[0m11.19    \u001b[0m | \u001b[0m0.7159   \u001b[0m | \u001b[0m0.1898   \u001b[0m |\n",
            "119/119 [==============================] - 0s 475us/step\n",
            "119/119 [==============================] - 0s 475us/step\n",
            "119/119 [==============================] - 0s 475us/step\n",
            "119/119 [==============================] - 0s 489us/step\n",
            "119/119 [==============================] - 0s 492us/step\n",
            "| \u001b[0m9        \u001b[0m | \u001b[0m2.224e+13\u001b[0m | \u001b[0m0.745    \u001b[0m | \u001b[0m703.5    \u001b[0m | \u001b[0m0.3622   \u001b[0m | \u001b[0m0.1881   \u001b[0m | \u001b[0m61.19    \u001b[0m | \u001b[0m4.58     \u001b[0m | \u001b[0m3.075    \u001b[0m | \u001b[0m0.6113   \u001b[0m | \u001b[0m52.73    \u001b[0m | \u001b[0m0.7096   \u001b[0m | \u001b[0m0.1152   \u001b[0m |\n",
            "119/119 [==============================] - 0s 458us/step\n",
            "119/119 [==============================] - 0s 467us/step\n",
            "119/119 [==============================] - 0s 450us/step\n",
            "119/119 [==============================] - 0s 458us/step\n",
            "119/119 [==============================] - 0s 467us/step\n",
            "| \u001b[0m10       \u001b[0m | \u001b[0m2.224e+13\u001b[0m | \u001b[0m0.7355   \u001b[0m | \u001b[0m902.4    \u001b[0m | \u001b[0m0.5191   \u001b[0m | \u001b[0m0.2041   \u001b[0m | \u001b[0m54.84    \u001b[0m | \u001b[0m4.887    \u001b[0m | \u001b[0m2.461    \u001b[0m | \u001b[0m0.6265   \u001b[0m | \u001b[0m33.25    \u001b[0m | \u001b[0m0.6813   \u001b[0m | \u001b[0m0.8766   \u001b[0m |\n",
            "119/119 [==============================] - 0s 433us/step\n",
            "119/119 [==============================] - 0s 441us/step\n",
            "119/119 [==============================] - 0s 467us/step\n",
            "119/119 [==============================] - 0s 441us/step\n",
            "119/119 [==============================] - 0s 441us/step\n",
            "| \u001b[0m11       \u001b[0m | \u001b[0m2.22e+13 \u001b[0m | \u001b[0m0.2498   \u001b[0m | \u001b[0m314.1    \u001b[0m | \u001b[0m0.8254   \u001b[0m | \u001b[0m0.1396   \u001b[0m | \u001b[0m47.05    \u001b[0m | \u001b[0m4.735    \u001b[0m | \u001b[0m2.818    \u001b[0m | \u001b[0m0.4993   \u001b[0m | \u001b[0m14.13    \u001b[0m | \u001b[0m0.119    \u001b[0m | \u001b[0m0.538    \u001b[0m |\n",
            "119/119 [==============================] - 0s 492us/step\n",
            "119/119 [==============================] - 0s 483us/step\n",
            "119/119 [==============================] - 0s 500us/step\n",
            "119/119 [==============================] - 0s 483us/step\n",
            "119/119 [==============================] - 0s 475us/step\n",
            "| \u001b[0m12       \u001b[0m | \u001b[0m2.22e+13 \u001b[0m | \u001b[0m0.06424  \u001b[0m | \u001b[0m440.4    \u001b[0m | \u001b[0m0.3781   \u001b[0m | \u001b[0m0.1827   \u001b[0m | \u001b[0m85.91    \u001b[0m | \u001b[0m1.732    \u001b[0m | \u001b[0m4.148    \u001b[0m | \u001b[0m0.3183   \u001b[0m | \u001b[0m79.44    \u001b[0m | \u001b[0m0.9149   \u001b[0m | \u001b[0m0.2263   \u001b[0m |\n",
            "119/119 [==============================] - 0s 488us/step\n",
            "119/119 [==============================] - 0s 534us/step\n",
            "119/119 [==============================] - 0s 543us/step\n",
            "119/119 [==============================] - 0s 500us/step\n",
            "119/119 [==============================] - 0s 500us/step\n",
            "| \u001b[0m13       \u001b[0m | \u001b[0m2.224e+13\u001b[0m | \u001b[0m0.9912   \u001b[0m | \u001b[0m449.2    \u001b[0m | \u001b[0m0.8856   \u001b[0m | \u001b[0m0.2081   \u001b[0m | \u001b[0m24.36    \u001b[0m | \u001b[0m1.807    \u001b[0m | \u001b[0m4.437    \u001b[0m | \u001b[0m0.6641   \u001b[0m | \u001b[0m88.55    \u001b[0m | \u001b[0m0.7237   \u001b[0m | \u001b[0m0.09194  \u001b[0m |\n",
            "119/119 [==============================] - 0s 448us/step\n",
            "119/119 [==============================] - 0s 416us/step\n",
            "119/119 [==============================] - 0s 424us/step\n",
            "119/119 [==============================] - 0s 424us/step\n",
            "119/119 [==============================] - 0s 433us/step\n",
            "| \u001b[0m14       \u001b[0m | \u001b[0m2.22e+13 \u001b[0m | \u001b[0m0.03175  \u001b[0m | \u001b[0m345.6    \u001b[0m | \u001b[0m0.2761   \u001b[0m | \u001b[0m0.202    \u001b[0m | \u001b[0m65.64    \u001b[0m | \u001b[0m2.509    \u001b[0m | \u001b[0m2.138    \u001b[0m | \u001b[0m0.2106   \u001b[0m | \u001b[0m39.78    \u001b[0m | \u001b[0m0.3645   \u001b[0m | \u001b[0m0.2026   \u001b[0m |\n",
            "119/119 [==============================] - 0s 509us/step\n",
            "119/119 [==============================] - 0s 509us/step\n",
            "119/119 [==============================] - 0s 492us/step\n",
            "119/119 [==============================] - 0s 509us/step\n",
            "119/119 [==============================] - 0s 500us/step\n",
            "| \u001b[0m15       \u001b[0m | \u001b[0m2.224e+13\u001b[0m | \u001b[0m0.6069   \u001b[0m | \u001b[0m250.4    \u001b[0m | \u001b[0m0.7315   \u001b[0m | \u001b[0m0.2202   \u001b[0m | \u001b[0m67.21    \u001b[0m | \u001b[0m3.868    \u001b[0m | \u001b[0m3.853    \u001b[0m | \u001b[0m0.7781   \u001b[0m | \u001b[0m71.56    \u001b[0m | \u001b[0m0.7979   \u001b[0m | \u001b[0m0.589    \u001b[0m |\n",
            "119/119 [==============================] - 0s 458us/step\n",
            "119/119 [==============================] - 0s 467us/step\n",
            "119/119 [==============================] - 0s 450us/step\n",
            "119/119 [==============================] - 0s 458us/step\n",
            "119/119 [==============================] - 0s 467us/step\n",
            "| \u001b[0m16       \u001b[0m | \u001b[0m2.223e+13\u001b[0m | \u001b[0m0.8611   \u001b[0m | \u001b[0m553.8    \u001b[0m | \u001b[0m0.388    \u001b[0m | \u001b[0m0.08434  \u001b[0m | \u001b[0m27.63    \u001b[0m | \u001b[0m2.734    \u001b[0m | \u001b[0m3.705    \u001b[0m | \u001b[0m0.2582   \u001b[0m | \u001b[0m40.57    \u001b[0m | \u001b[0m0.6354   \u001b[0m | \u001b[0m0.681    \u001b[0m |\n",
            "119/119 [==============================] - 0s 516us/step\n",
            "119/119 [==============================] - 0s 509us/step\n",
            "119/119 [==============================] - 0s 517us/step\n",
            "119/119 [==============================] - 0s 509us/step\n",
            "119/119 [==============================] - 0s 500us/step\n",
            "| \u001b[0m17       \u001b[0m | \u001b[0m2.224e+13\u001b[0m | \u001b[0m0.3567   \u001b[0m | \u001b[0m604.8    \u001b[0m | \u001b[0m0.4119   \u001b[0m | \u001b[0m0.2227   \u001b[0m | \u001b[0m31.6     \u001b[0m | \u001b[0m3.925    \u001b[0m | \u001b[0m3.062    \u001b[0m | \u001b[0m0.3393   \u001b[0m | \u001b[0m93.31    \u001b[0m | \u001b[0m0.9734   \u001b[0m | \u001b[0m0.5595   \u001b[0m |\n",
            "119/119 [==============================] - 0s 509us/step\n",
            "119/119 [==============================] - 0s 500us/step\n",
            "119/119 [==============================] - 0s 542us/step\n",
            "119/119 [==============================] - 0s 526us/step\n",
            "119/119 [==============================] - 0s 543us/step\n",
            "| \u001b[0m18       \u001b[0m | \u001b[0m2.224e+13\u001b[0m | \u001b[0m0.1109   \u001b[0m | \u001b[0m737.7    \u001b[0m | \u001b[0m0.9307   \u001b[0m | \u001b[0m0.08556  \u001b[0m | \u001b[0m29.43    \u001b[0m | \u001b[0m4.402    \u001b[0m | \u001b[0m3.782    \u001b[0m | \u001b[0m0.9006   \u001b[0m | \u001b[0m94.77    \u001b[0m | \u001b[0m0.5163   \u001b[0m | \u001b[0m0.6949   \u001b[0m |\n",
            "119/119 [==============================] - 0s 416us/step\n",
            "119/119 [==============================] - 0s 433us/step\n",
            "119/119 [==============================] - 0s 416us/step\n",
            "119/119 [==============================] - 0s 450us/step\n",
            "119/119 [==============================] - 0s 433us/step\n",
            "| \u001b[0m19       \u001b[0m | \u001b[0m2.22e+13 \u001b[0m | \u001b[0m0.4372   \u001b[0m | \u001b[0m899.2    \u001b[0m | \u001b[0m0.6551   \u001b[0m | \u001b[0m0.02753  \u001b[0m | \u001b[0m43.47    \u001b[0m | \u001b[0m2.187    \u001b[0m | \u001b[0m2.334    \u001b[0m | \u001b[0m0.1267   \u001b[0m | \u001b[0m63.06    \u001b[0m | \u001b[0m0.4873   \u001b[0m | \u001b[0m0.1037   \u001b[0m |\n",
            "119/119 [==============================] - 0s 450us/step\n",
            "119/119 [==============================] - 0s 441us/step\n",
            "119/119 [==============================] - 0s 450us/step\n",
            "119/119 [==============================] - 0s 458us/step\n",
            "119/119 [==============================] - 0s 450us/step\n",
            "| \u001b[0m20       \u001b[0m | \u001b[0m2.221e+13\u001b[0m | \u001b[0m0.3013   \u001b[0m | \u001b[0m701.7    \u001b[0m | \u001b[0m0.07346  \u001b[0m | \u001b[0m0.05054  \u001b[0m | \u001b[0m76.62    \u001b[0m | \u001b[0m3.378    \u001b[0m | \u001b[0m3.057    \u001b[0m | \u001b[0m0.54     \u001b[0m | \u001b[0m33.33    \u001b[0m | \u001b[0m0.6661   \u001b[0m | \u001b[0m0.02819  \u001b[0m |\n",
            "119/119 [==============================] - 0s 450us/step\n",
            "119/119 [==============================] - 0s 458us/step\n",
            "119/119 [==============================] - 0s 450us/step\n",
            "119/119 [==============================] - 0s 441us/step\n",
            "119/119 [==============================] - 0s 445us/step\n",
            "| \u001b[0m21       \u001b[0m | \u001b[0m2.224e+13\u001b[0m | \u001b[0m0.6874   \u001b[0m | \u001b[0m667.3    \u001b[0m | \u001b[0m0.5589   \u001b[0m | \u001b[0m0.04195  \u001b[0m | \u001b[0m30.23    \u001b[0m | \u001b[0m3.178    \u001b[0m | \u001b[0m3.264    \u001b[0m | \u001b[0m0.8174   \u001b[0m | \u001b[0m41.98    \u001b[0m | \u001b[0m0.5924   \u001b[0m | \u001b[0m0.6753   \u001b[0m |\n",
            "119/119 [==============================] - 0s 467us/step\n",
            "119/119 [==============================] - 0s 450us/step\n",
            "119/119 [==============================] - 0s 441us/step\n",
            "119/119 [==============================] - 0s 441us/step\n",
            "119/119 [==============================] - 0s 455us/step\n",
            "| \u001b[0m22       \u001b[0m | \u001b[0m2.224e+13\u001b[0m | \u001b[0m0.09972  \u001b[0m | \u001b[0m783.9    \u001b[0m | \u001b[0m0.7164   \u001b[0m | \u001b[0m0.2642   \u001b[0m | \u001b[0m53.48    \u001b[0m | \u001b[0m1.875    \u001b[0m | \u001b[0m3.743    \u001b[0m | \u001b[0m0.9643   \u001b[0m | \u001b[0m61.84    \u001b[0m | \u001b[0m0.2376   \u001b[0m | \u001b[0m0.3408   \u001b[0m |\n",
            "119/119 [==============================] - 0s 441us/step\n",
            "119/119 [==============================] - 0s 450us/step\n",
            "119/119 [==============================] - 0s 467us/step\n",
            "119/119 [==============================] - 0s 441us/step\n",
            "119/119 [==============================] - 0s 483us/step\n",
            "| \u001b[0m23       \u001b[0m | \u001b[0m2.22e+13 \u001b[0m | \u001b[0m0.6347   \u001b[0m | \u001b[0m741.3    \u001b[0m | \u001b[0m0.6444   \u001b[0m | \u001b[0m0.201    \u001b[0m | \u001b[0m66.52    \u001b[0m | \u001b[0m2.763    \u001b[0m | \u001b[0m3.407    \u001b[0m | \u001b[0m0.3842   \u001b[0m | \u001b[0m33.18    \u001b[0m | \u001b[0m0.9529   \u001b[0m | \u001b[0m0.5877   \u001b[0m |\n",
            "119/119 [==============================] - 0s 492us/step\n",
            "119/119 [==============================] - 0s 483us/step\n",
            "119/119 [==============================] - 0s 483us/step\n",
            "119/119 [==============================] - 0s 475us/step\n",
            "119/119 [==============================] - 0s 492us/step\n",
            "| \u001b[0m24       \u001b[0m | \u001b[0m2.223e+13\u001b[0m | \u001b[0m0.826    \u001b[0m | \u001b[0m594.4    \u001b[0m | \u001b[0m0.681    \u001b[0m | \u001b[0m0.1518   \u001b[0m | \u001b[0m38.07    \u001b[0m | \u001b[0m2.38     \u001b[0m | \u001b[0m4.119    \u001b[0m | \u001b[0m0.1059   \u001b[0m | \u001b[0m83.26    \u001b[0m | \u001b[0m0.1024   \u001b[0m | \u001b[0m0.6199   \u001b[0m |\n",
            "119/119 [==============================] - 0s 424us/step\n",
            "119/119 [==============================] - 0s 424us/step\n",
            "119/119 [==============================] - 0s 428us/step\n",
            "119/119 [==============================] - 0s 420us/step\n",
            "119/119 [==============================] - 0s 416us/step\n",
            "| \u001b[0m25       \u001b[0m | \u001b[0m2.223e+13\u001b[0m | \u001b[0m0.08354  \u001b[0m | \u001b[0m976.4    \u001b[0m | \u001b[0m0.6527   \u001b[0m | \u001b[0m0.2858   \u001b[0m | \u001b[0m76.45    \u001b[0m | \u001b[0m1.421    \u001b[0m | \u001b[0m2.57     \u001b[0m | \u001b[0m0.7721   \u001b[0m | \u001b[0m61.96    \u001b[0m | \u001b[0m0.3429   \u001b[0m | \u001b[0m0.02441  \u001b[0m |\n",
            "119/119 [==============================] - 0s 483us/step\n",
            "119/119 [==============================] - 0s 492us/step\n",
            "119/119 [==============================] - 0s 475us/step\n",
            "119/119 [==============================] - 0s 467us/step\n",
            "119/119 [==============================] - 0s 475us/step\n",
            "| \u001b[0m26       \u001b[0m | \u001b[0m2.224e+13\u001b[0m | \u001b[0m0.6734   \u001b[0m | \u001b[0m782.3    \u001b[0m | \u001b[0m0.41     \u001b[0m | \u001b[0m0.06132  \u001b[0m | \u001b[0m53.62    \u001b[0m | \u001b[0m4.204    \u001b[0m | \u001b[0m2.574    \u001b[0m | \u001b[0m0.425    \u001b[0m | \u001b[0m62.47    \u001b[0m | \u001b[0m0.7154   \u001b[0m | \u001b[0m0.9959   \u001b[0m |\n",
            "119/119 [==============================] - 0s 458us/step\n",
            "119/119 [==============================] - 0s 441us/step\n",
            "119/119 [==============================] - 0s 467us/step\n",
            "119/119 [==============================] - 0s 441us/step\n",
            "119/119 [==============================] - 0s 441us/step\n",
            "| \u001b[0m27       \u001b[0m | \u001b[0m2.22e+13 \u001b[0m | \u001b[0m0.3582   \u001b[0m | \u001b[0m912.3    \u001b[0m | \u001b[0m0.4575   \u001b[0m | \u001b[0m0.1426   \u001b[0m | \u001b[0m21.33    \u001b[0m | \u001b[0m2.742    \u001b[0m | \u001b[0m1.272    \u001b[0m | \u001b[0m0.8466   \u001b[0m | \u001b[0m48.85    \u001b[0m | \u001b[0m0.7694   \u001b[0m | \u001b[0m0.2891   \u001b[0m |\n",
            "119/119 [==============================] - 0s 465us/step\n",
            "119/119 [==============================] - 0s 458us/step\n",
            "119/119 [==============================] - 0s 467us/step\n",
            "119/119 [==============================] - 0s 492us/step\n",
            "119/119 [==============================] - 0s 458us/step\n",
            "| \u001b[0m28       \u001b[0m | \u001b[0m2.223e+13\u001b[0m | \u001b[0m0.2797   \u001b[0m | \u001b[0m782.7    \u001b[0m | \u001b[0m0.855    \u001b[0m | \u001b[0m0.02165  \u001b[0m | \u001b[0m46.68    \u001b[0m | \u001b[0m2.538    \u001b[0m | \u001b[0m2.36     \u001b[0m | \u001b[0m0.2875   \u001b[0m | \u001b[0m66.37    \u001b[0m | \u001b[0m0.9824   \u001b[0m | \u001b[0m0.5696   \u001b[0m |\n",
            "119/119 [==============================] - 0s 416us/step\n",
            "119/119 [==============================] - 0s 407us/step\n",
            "119/119 [==============================] - 0s 416us/step\n",
            "119/119 [==============================] - 0s 416us/step\n",
            "119/119 [==============================] - 0s 407us/step\n",
            "| \u001b[0m29       \u001b[0m | \u001b[0m2.22e+13 \u001b[0m | \u001b[0m0.5069   \u001b[0m | \u001b[0m787.4    \u001b[0m | \u001b[0m0.05037  \u001b[0m | \u001b[0m0.1153   \u001b[0m | \u001b[0m61.29    \u001b[0m | \u001b[0m1.165    \u001b[0m | \u001b[0m1.009    \u001b[0m | \u001b[0m0.03512  \u001b[0m | \u001b[0m64.85    \u001b[0m | \u001b[0m0.4468   \u001b[0m | \u001b[0m0.6947   \u001b[0m |\n",
            "=============================================================================================================================================================\n"
          ]
        }
      ],
      "source": [
        "params_nn3 ={\n",
        "    'neurons': (10, 100),\n",
        "    'activation':(0.01, 1),\n",
        "    'optimizer':(0,1),\n",
        "    'learning_rate':(0.01, 1),\n",
        "    'batch_size':(200, 1000),\n",
        "    'epochs':(20, 100),\n",
        "    'layers1':(1,5),\n",
        "    'layers2':(1,5),\n",
        "    'normalization':(0,1),\n",
        "    'dropout':(0,1),\n",
        "    'dropout_rate':(0,0.3)\n",
        "}\n",
        "# Run Bayesian Optimization\n",
        "nn_bo3 = BayesianOptimization(function3, params_nn3, random_state=2023)\n",
        "nn_bo3.maximize(init_points=25, n_iter=4)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "87d60e97",
      "metadata": {
        "id": "87d60e97"
      },
      "source": [
        "**BEST PARAMS**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "412831db",
      "metadata": {
        "id": "412831db",
        "outputId": "13a65099-c56b-476b-990e-5fd497020d89"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'activation': 'relu',\n",
              " 'batch_size': 501,\n",
              " 'dropout': 0.1840541418275664,\n",
              " 'dropout_rate': 0.031185550905878476,\n",
              " 'epochs': 56,\n",
              " 'layers1': 2,\n",
              " 'layers2': 3,\n",
              " 'learning_rate': 0.931226639688736,\n",
              " 'neurons': 78,\n",
              " 'normalization': 0.7707642376587938,\n",
              " 'optimizer': <keras.optimizers.legacy.adam.Adam at 0x121806ac520>}"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "params_nn_3 = nn_bo3.max['params']\n",
        "learning_rate = params_nn_3['learning_rate']\n",
        "activationL = ['relu', 'relu']\n",
        "params_nn_3['activation'] = activationL[round(params_nn_3['activation'])]\n",
        "params_nn_3['batch_size'] = round(params_nn_3['batch_size'])\n",
        "params_nn_3['epochs'] = round(params_nn_3['epochs'])\n",
        "params_nn_3['layers1'] = round(params_nn_3['layers1'])\n",
        "params_nn_3['layers2'] = round(params_nn_3['layers2'])\n",
        "params_nn_3['neurons'] = round(params_nn_3['neurons'])\n",
        "optimizerL = ['Adam', 'Adam']\n",
        "optimizerD= {'Adam':Adam(lr=learning_rate)}\n",
        "params_nn_3['optimizer'] = optimizerD[optimizerL[round(params_nn_3['optimizer'])]]\n",
        "params_nn_3"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "46801020",
      "metadata": {
        "id": "46801020"
      },
      "source": [
        "**MODEL**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "08e97414",
      "metadata": {
        "scrolled": true,
        "id": "08e97414",
        "outputId": "9914b303-ea00-4191-9bd4-b820ec692570"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/56\n",
            "38/38 [==============================] - 1s 3ms/step - loss: 23868536258560.0000 - mse: 23868536258560.0000\n",
            "Epoch 2/56\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 23854676180992.0000 - mse: 23854676180992.0000\n",
            "Epoch 3/56\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 23129390841856.0000 - mse: 23129390841856.0000\n",
            "Epoch 4/56\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 19071137480704.0000 - mse: 19071137480704.0000\n",
            "Epoch 5/56\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 14077956980736.0000 - mse: 14077956980736.0000\n",
            "Epoch 6/56\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 14431522127872.0000 - mse: 14431522127872.0000\n",
            "Epoch 7/56\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 13020834037760.0000 - mse: 13020834037760.0000\n",
            "Epoch 8/56\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 12410562805760.0000 - mse: 12410562805760.0000\n",
            "Epoch 9/56\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 12672880869376.0000 - mse: 12672880869376.0000\n",
            "Epoch 10/56\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 12569034096640.0000 - mse: 12569034096640.0000\n",
            "Epoch 11/56\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 10479186477056.0000 - mse: 10479186477056.0000\n",
            "Epoch 12/56\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 10489825329152.0000 - mse: 10489825329152.0000\n",
            "Epoch 13/56\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 11668130103296.0000 - mse: 11668130103296.0000\n",
            "Epoch 14/56\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 8761139789824.0000 - mse: 8761139789824.0000\n",
            "Epoch 15/56\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 8844192251904.0000 - mse: 8844192251904.0000\n",
            "Epoch 16/56\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 8087042260992.0000 - mse: 8087042260992.0000\n",
            "Epoch 17/56\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 5849798934528.0000 - mse: 5849798934528.0000\n",
            "Epoch 18/56\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 6560975683584.0000 - mse: 6560975683584.0000\n",
            "Epoch 19/56\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 5273527255040.0000 - mse: 5273527779328.0000\n",
            "Epoch 20/56\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 4520303132672.0000 - mse: 4520303132672.0000\n",
            "Epoch 21/56\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 4176492101632.0000 - mse: 4176492101632.0000\n",
            "Epoch 22/56\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 3821145161728.0000 - mse: 3821145161728.0000\n",
            "Epoch 23/56\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 3248196157440.0000 - mse: 3248196157440.0000\n",
            "Epoch 24/56\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 7083645206528.0000 - mse: 7083645206528.0000\n",
            "Epoch 25/56\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 3170690662400.0000 - mse: 3170690662400.0000\n",
            "Epoch 26/56\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 4534880960512.0000 - mse: 4534880960512.0000\n",
            "Epoch 27/56\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 2725467652096.0000 - mse: 2725467652096.0000\n",
            "Epoch 28/56\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 2583316660224.0000 - mse: 2583316660224.0000\n",
            "Epoch 29/56\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 2167820779520.0000 - mse: 2167820779520.0000\n",
            "Epoch 30/56\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 2108010528768.0000 - mse: 2108010528768.0000\n",
            "Epoch 31/56\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 2790108430336.0000 - mse: 2790108430336.0000\n",
            "Epoch 32/56\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 1703830880256.0000 - mse: 1703830880256.0000\n",
            "Epoch 33/56\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 2441742647296.0000 - mse: 2441742647296.0000\n",
            "Epoch 34/56\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 2313272164352.0000 - mse: 2313272164352.0000\n",
            "Epoch 35/56\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 2072486608896.0000 - mse: 2072486608896.0000\n",
            "Epoch 36/56\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 2549643476992.0000 - mse: 2549643476992.0000\n",
            "Epoch 37/56\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 2269431463936.0000 - mse: 2269431463936.0000\n",
            "Epoch 38/56\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 2216037711872.0000 - mse: 2216037711872.0000\n",
            "Epoch 39/56\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 2150909345792.0000 - mse: 2150909345792.0000\n",
            "Epoch 40/56\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 2093650280448.0000 - mse: 2093650280448.0000\n",
            "Epoch 41/56\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 2203964669952.0000 - mse: 2203964669952.0000\n",
            "Epoch 42/56\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 3329298792448.0000 - mse: 3329298792448.0000\n",
            "Epoch 43/56\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 2294493478912.0000 - mse: 2294493478912.0000\n",
            "Epoch 44/56\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 2166069657600.0000 - mse: 2166069657600.0000\n",
            "Epoch 45/56\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 2982417006592.0000 - mse: 2982417006592.0000\n",
            "Epoch 46/56\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 2296746606592.0000 - mse: 2296746606592.0000\n",
            "Epoch 47/56\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 4364432048128.0000 - mse: 4364432048128.0000\n",
            "Epoch 48/56\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 2029547814912.0000 - mse: 2029547814912.0000\n",
            "Epoch 49/56\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 5261389463552.0000 - mse: 5261389463552.0000\n",
            "Epoch 50/56\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 2362056114176.0000 - mse: 2362056114176.0000\n",
            "Epoch 51/56\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 2214214500352.0000 - mse: 2214214500352.0000\n",
            "Epoch 52/56\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 2966835691520.0000 - mse: 2966835691520.0000\n",
            "Epoch 53/56\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 2209324728320.0000 - mse: 2209324728320.0000\n",
            "Epoch 54/56\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 2611199606784.0000 - mse: 2611199606784.0000\n",
            "Epoch 55/56\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 3996112912384.0000 - mse: 3996112912384.0000\n",
            "Epoch 56/56\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 4375807000576.0000 - mse: 4375807000576.0000\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x12180951cd0>"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_3 = Sequential()\n",
        "model_3.add(Dense(params_nn_3['neurons'], input_dim=21, activation=params_nn_3['activation']))\n",
        "if params_nn_3['normalization'] > 0.5:\n",
        "    model_3.add(BatchNormalization())\n",
        "for i in range(params_nn_3['layers1']):\n",
        "    model_3.add(Dense(params_nn_3['neurons'], activation=params_nn_3['activation']))\n",
        "if params_nn_3['dropout'] > 0.5:\n",
        "    model_3.add(Dropout(params_nn_3['dropout_rate'], seed=2023))\n",
        "for i in range(params_nn_3['layers2']):\n",
        "    model_3.add(Dense(params_nn_3['neurons'], activation=params_nn_3['activation']))\n",
        "model_3.add(Dense(1))\n",
        "model_3.compile(loss='mse', optimizer='adam', metrics=['mse'])\n",
        "    \n",
        "model_3.fit(X_train_f_reg_df, y_train, epochs=params_nn_3['epochs'], batch_size=params_nn_3['batch_size'],verbose=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b6349e0d",
      "metadata": {
        "id": "b6349e0d"
      },
      "source": [
        "**EVALUATION**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cefa865b",
      "metadata": {
        "id": "cefa865b",
        "outputId": "19937a35-d54e-43e0-c06b-506bcdc043f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "149/149 [==============================] - 0s 480us/step\n",
            "Standard Deviation: price    5.275527e+06\n",
            "dtype: float64\n",
            "Range: price    342535000\n",
            "dtype: int64\n",
            "Mean squared error: 900300898706.1031\n",
            "Mean absolute error: 459639.27273386414\n",
            "RMSE: 948841.8723402247\n",
            "R-squared: 0.9676445422890719\n",
            "Percentage of error compared to SD: price    8.71267\n",
            "dtype: float64\n"
          ]
        }
      ],
      "source": [
        "# For Non-scaled training data\n",
        "X_test_f_reg_df = pd.DataFrame(X_test_f_reg_arr)\n",
        "predicted_prices3 = model_3.predict(X_test_f_reg_df)\n",
        "mse3 = mean_squared_error(y_test, predicted_prices3)\n",
        "\n",
        "rmse3 = mean_squared_error(y_test, predicted_prices3, squared=False)\n",
        "\n",
        "# Calculate mean absolute error\n",
        "mae3 = mean_absolute_error(y_test, predicted_prices3)\n",
        "\n",
        "# Calculate coefficient of determination (R-squared)\n",
        "r2_3 = r2_score(y_test, predicted_prices3)\n",
        "\n",
        "print('Standard Deviation:', y_test.std())\n",
        "print('Range:', y_test.max() - y_test.min())\n",
        "print('Mean squared error:', mse3)\n",
        "print('Mean absolute error:', mae3)\n",
        "print('RMSE:', rmse3)\n",
        "print('R-squared:', r2_3)\n",
        "print('Percentage of error compared to SD:', mae3/y_test.std() * 100)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "030b7270",
      "metadata": {
        "id": "030b7270"
      },
      "source": [
        "# With SelectKBest Mutual Info Regression Training Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aa82b6fb",
      "metadata": {
        "id": "aa82b6fb",
        "outputId": "b8d0e1cf-ef08-4e84-d7aa-f94113f97409"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10.0</td>\n",
              "      <td>53.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.209648</td>\n",
              "      <td>52.000000</td>\n",
              "      <td>18041.0</td>\n",
              "      <td>41.000000</td>\n",
              "      <td>26.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>18.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.048992</td>\n",
              "      <td>14.022488</td>\n",
              "      <td>1541.0</td>\n",
              "      <td>13.027174</td>\n",
              "      <td>16.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10.0</td>\n",
              "      <td>87.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.209648</td>\n",
              "      <td>14.022488</td>\n",
              "      <td>18041.0</td>\n",
              "      <td>13.027174</td>\n",
              "      <td>46.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6.0</td>\n",
              "      <td>141.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.197689</td>\n",
              "      <td>14.022488</td>\n",
              "      <td>3579.0</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>56.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11.0</td>\n",
              "      <td>85.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.182874</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>10121.0</td>\n",
              "      <td>13.027174</td>\n",
              "      <td>26.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>4.8</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18957</th>\n",
              "      <td>11.0</td>\n",
              "      <td>128.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>0.350559</td>\n",
              "      <td>14.022488</td>\n",
              "      <td>14151.0</td>\n",
              "      <td>13.027174</td>\n",
              "      <td>6.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>4.8</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18958</th>\n",
              "      <td>19.0</td>\n",
              "      <td>46.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.066560</td>\n",
              "      <td>14.022488</td>\n",
              "      <td>17081.0</td>\n",
              "      <td>13.027174</td>\n",
              "      <td>6.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18959</th>\n",
              "      <td>19.0</td>\n",
              "      <td>71.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>0.140742</td>\n",
              "      <td>14.022488</td>\n",
              "      <td>17131.0</td>\n",
              "      <td>13.027174</td>\n",
              "      <td>46.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18960</th>\n",
              "      <td>17.0</td>\n",
              "      <td>63.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.087684</td>\n",
              "      <td>14.022488</td>\n",
              "      <td>6031.0</td>\n",
              "      <td>13.027174</td>\n",
              "      <td>56.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>4.8</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18961</th>\n",
              "      <td>19.0</td>\n",
              "      <td>96.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.227100</td>\n",
              "      <td>14.022488</td>\n",
              "      <td>28011.0</td>\n",
              "      <td>13.027174</td>\n",
              "      <td>6.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>4.1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>18962 rows × 21 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         0      1     2         3          4        5          6     7     8   \\\n",
              "0      10.0   53.0   6.0  0.209648  52.000000  18041.0  41.000000  26.0  21.0   \n",
              "1      18.0   67.0   3.0  0.048992  14.022488   1541.0  13.027174  16.0  21.0   \n",
              "2      10.0   87.0   1.0  0.209648  14.022488  18041.0  13.027174  46.0  21.0   \n",
              "3       6.0  141.0   5.0  0.197689  14.022488   3579.0   2.000000  56.0  18.0   \n",
              "4      11.0   85.0   4.0  0.182874   5.000000  10121.0  13.027174  26.0  22.0   \n",
              "...     ...    ...   ...       ...        ...      ...        ...   ...   ...   \n",
              "18957  11.0  128.0   9.0  0.350559  14.022488  14151.0  13.027174   6.0  19.0   \n",
              "18958  19.0   46.0   5.0  0.066560  14.022488  17081.0  13.027174   6.0  22.0   \n",
              "18959  19.0   71.0  12.0  0.140742  14.022488  17131.0  13.027174  46.0  20.0   \n",
              "18960  17.0   63.0   2.0  0.087684  14.022488   6031.0  13.027174  56.0  23.0   \n",
              "18961  19.0   96.0   6.0  0.227100  14.022488  28011.0  13.027174   6.0  18.0   \n",
              "\n",
              "        9    10   11   12   13   14   15   16   17   18   19   20  \n",
              "0      4.0  0.0  0.0  1.0  1.0  0.0  0.0  1.0  1.0  0.0  0.0  1.0  \n",
              "1      4.0  1.0  0.0  0.0  1.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  \n",
              "2      4.0  0.0  0.0  1.0  1.0  0.0  0.0  1.0  1.0  0.0  0.0  1.0  \n",
              "3      4.0  1.0  0.0  0.0  1.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  \n",
              "4      4.8  0.0  0.0  1.0  0.0  1.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
              "...    ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  \n",
              "18957  4.8  0.0  0.0  1.0  0.0  1.0  0.0  0.0  0.0  1.0  1.0  0.0  \n",
              "18958  4.0  0.0  1.0  0.0  0.0  1.0  1.0  0.0  0.0  1.0  0.0  1.0  \n",
              "18959  4.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0  1.0  0.0  0.0  1.0  \n",
              "18960  4.8  0.0  0.0  1.0  0.0  1.0  0.0  0.0  1.0  0.0  0.0  0.0  \n",
              "18961  4.1  0.0  1.0  0.0  0.0  1.0  1.0  0.0  0.0  1.0  0.0  1.0  \n",
              "\n",
              "[18962 rows x 21 columns]"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train_mi_reg_df = pd.DataFrame(X_train_mi_reg_arr)\n",
        "X_train_mi_reg_df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9c0aef96",
      "metadata": {
        "id": "9c0aef96"
      },
      "source": [
        "**Hyperparameter Tuning**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c9193e4c",
      "metadata": {
        "id": "c9193e4c"
      },
      "outputs": [],
      "source": [
        "def function4(neurons, activation, optimizer, learning_rate, batch_size, epochs,\n",
        "              layers1, layers2, normalization, dropout, dropout_rate):\n",
        "    optimizerL = ['Adam', 'Adam'] #Fixing optimizer to Adam\n",
        "    optimizerD= {'Adam':Adam(lr=learning_rate)}\n",
        "    activationL = ['relu', 'relu'] #Fixing activation to relu\n",
        "    neurons = round(neurons)\n",
        "    activation = activationL[round(activation)]\n",
        "    optimizer = optimizerD[optimizerL[round(optimizer)]]\n",
        "    batch_size = round(batch_size)\n",
        "    epochs = round(epochs)\n",
        "    layers1 = round(layers1)\n",
        "    layers2 = round(layers2)\n",
        "    def nn_cl_fun():\n",
        "        nn = Sequential()\n",
        "        nn.add(Dense(neurons, input_dim=21, activation=activation))\n",
        "        if normalization > 0.5:\n",
        "            nn.add(BatchNormalization())\n",
        "        for i in range(layers1):\n",
        "            nn.add(Dense(neurons, activation=activation))\n",
        "        if dropout > 0.5:\n",
        "            nn.add(Dropout(dropout_rate, seed=2023))\n",
        "        for i in range(layers2):\n",
        "            nn.add(Dense(neurons, activation=activation))\n",
        "        nn.add(Dense(1))\n",
        "        nn.compile(loss='mse', optimizer=optimizer, metrics=['mse'])\n",
        "        return nn\n",
        "    es = EarlyStopping(monitor='mse', mode='min', verbose=0, patience=20)\n",
        "    nn = KerasClassifier(build_fn=nn_cl_fun, epochs=epochs, batch_size=batch_size, verbose=0)\n",
        "    kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=2023)\n",
        "    score = cross_val_score(nn, X_train_mi_reg_df, y_train, scoring=score_acc, cv=kfold, fit_params={'callbacks':[es]}).mean()\n",
        "    return score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8aebe462",
      "metadata": {
        "scrolled": true,
        "id": "8aebe462",
        "outputId": "f1a7f465-43fb-4df5-c7d6-4c44aebc1770"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "|   iter    |  target   | activa... | batch_... |  dropout  | dropou... |  epochs   |  layers1  |  layers2  | learni... |  neurons  | normal... | optimizer |\n",
            "-------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "119/119 [==============================] - 0s 468us/step\n",
            "119/119 [==============================] - 0s 458us/step\n",
            "119/119 [==============================] - 0s 467us/step\n",
            "119/119 [==============================] - 0s 483us/step\n",
            "119/119 [==============================] - 0s 458us/step\n",
            "| \u001b[0m1        \u001b[0m | \u001b[0m2.223e+13\u001b[0m | \u001b[0m0.3288   \u001b[0m | \u001b[0m912.3    \u001b[0m | \u001b[0m0.5881   \u001b[0m | \u001b[0m0.03798  \u001b[0m | \u001b[0m31.31    \u001b[0m | \u001b[0m2.872    \u001b[0m | \u001b[0m1.088    \u001b[0m | \u001b[0m0.73     \u001b[0m | \u001b[0m57.19    \u001b[0m | \u001b[0m0.5449   \u001b[0m | \u001b[0m0.4564   \u001b[0m |\n",
            "119/119 [==============================] - 0s 441us/step\n",
            "119/119 [==============================] - 0s 441us/step\n",
            "119/119 [==============================] - 0s 448us/step\n",
            "119/119 [==============================] - 0s 467us/step\n",
            "119/119 [==============================] - 0s 441us/step\n",
            "| \u001b[0m2        \u001b[0m | \u001b[0m2.22e+13 \u001b[0m | \u001b[0m0.5064   \u001b[0m | \u001b[0m515.6    \u001b[0m | \u001b[0m0.1512   \u001b[0m | \u001b[0m0.1083   \u001b[0m | \u001b[0m32.97    \u001b[0m | \u001b[0m2.352    \u001b[0m | \u001b[0m1.721    \u001b[0m | \u001b[0m0.3971   \u001b[0m | \u001b[0m13.21    \u001b[0m | \u001b[0m0.5649   \u001b[0m | \u001b[0m0.2035   \u001b[0m |\n",
            "119/119 [==============================] - 0s 483us/step\n",
            "119/119 [==============================] - 0s 483us/step\n",
            "119/119 [==============================] - 0s 493us/step\n",
            "119/119 [==============================] - 0s 483us/step\n",
            "119/119 [==============================] - 0s 484us/step\n",
            "| \u001b[95m3        \u001b[0m | \u001b[95m2.224e+13\u001b[0m | \u001b[95m0.3274   \u001b[0m | \u001b[95m501.3    \u001b[0m | \u001b[95m0.1841   \u001b[0m | \u001b[95m0.03119  \u001b[0m | \u001b[95m56.39    \u001b[0m | \u001b[95m1.783    \u001b[0m | \u001b[95m2.514    \u001b[0m | \u001b[95m0.9312   \u001b[0m | \u001b[95m78.41    \u001b[0m | \u001b[95m0.7708   \u001b[0m | \u001b[95m0.5967   \u001b[0m |\n",
            "119/119 [==============================] - 0s 458us/step\n",
            "119/119 [==============================] - 0s 458us/step\n",
            "119/119 [==============================] - 0s 450us/step\n",
            "119/119 [==============================] - 0s 450us/step\n",
            "119/119 [==============================] - 0s 458us/step\n",
            "| \u001b[0m4        \u001b[0m | \u001b[0m2.224e+13\u001b[0m | \u001b[0m0.7937   \u001b[0m | \u001b[0m848.3    \u001b[0m | \u001b[0m0.9806   \u001b[0m | \u001b[0m0.2654   \u001b[0m | \u001b[0m28.78    \u001b[0m | \u001b[0m4.279    \u001b[0m | \u001b[0m2.23     \u001b[0m | \u001b[0m0.2689   \u001b[0m | \u001b[0m46.52    \u001b[0m | \u001b[0m0.5534   \u001b[0m | \u001b[0m0.6255   \u001b[0m |\n",
            "119/119 [==============================] - 0s 467us/step\n",
            "119/119 [==============================] - 0s 441us/step\n",
            "119/119 [==============================] - 0s 450us/step\n",
            "119/119 [==============================] - 0s 458us/step\n",
            "119/119 [==============================] - 0s 458us/step\n",
            "| \u001b[95m5        \u001b[0m | \u001b[95m2.224e+13\u001b[0m | \u001b[95m0.08797  \u001b[0m | \u001b[95m977.8    \u001b[0m | \u001b[95m0.4113   \u001b[0m | \u001b[95m0.2165   \u001b[0m | \u001b[95m73.06    \u001b[0m | \u001b[95m1.873    \u001b[0m | \u001b[95m1.749    \u001b[0m | \u001b[95m0.7325   \u001b[0m | \u001b[95m87.7     \u001b[0m | \u001b[95m0.3917   \u001b[0m | \u001b[95m0.11     \u001b[0m |\n",
            "119/119 [==============================] - 0s 492us/step\n",
            "119/119 [==============================] - 0s 510us/step\n",
            "119/119 [==============================] - 0s 500us/step\n",
            "119/119 [==============================] - 0s 500us/step\n",
            "119/119 [==============================] - 0s 526us/step\n",
            "| \u001b[0m6        \u001b[0m | \u001b[0m2.224e+13\u001b[0m | \u001b[0m0.9137   \u001b[0m | \u001b[0m485.6    \u001b[0m | \u001b[0m0.413    \u001b[0m | \u001b[0m0.05506  \u001b[0m | \u001b[0m66.88    \u001b[0m | \u001b[0m4.423    \u001b[0m | \u001b[0m4.159    \u001b[0m | \u001b[0m0.09696  \u001b[0m | \u001b[0m93.97    \u001b[0m | \u001b[0m0.5      \u001b[0m | \u001b[0m0.3643   \u001b[0m |\n",
            "119/119 [==============================] - 0s 458us/step\n",
            "119/119 [==============================] - 0s 483us/step\n",
            "119/119 [==============================] - 0s 543us/step\n",
            "119/119 [==============================] - 0s 450us/step\n",
            "119/119 [==============================] - 0s 475us/step\n",
            "| \u001b[0m7        \u001b[0m | \u001b[0m2.223e+13\u001b[0m | \u001b[0m0.4888   \u001b[0m | \u001b[0m612.2    \u001b[0m | \u001b[0m0.9946   \u001b[0m | \u001b[0m0.226    \u001b[0m | \u001b[0m49.27    \u001b[0m | \u001b[0m3.445    \u001b[0m | \u001b[0m2.678    \u001b[0m | \u001b[0m0.1008   \u001b[0m | \u001b[0m58.14    \u001b[0m | \u001b[0m0.3408   \u001b[0m | \u001b[0m0.01834  \u001b[0m |\n",
            "119/119 [==============================] - 0s 465us/step\n",
            "119/119 [==============================] - 0s 441us/step\n",
            "119/119 [==============================] - 0s 450us/step\n",
            "119/119 [==============================] - 0s 433us/step\n",
            "119/119 [==============================] - 0s 441us/step\n",
            "| \u001b[0m8        \u001b[0m | \u001b[0m2.22e+13 \u001b[0m | \u001b[0m0.6074   \u001b[0m | \u001b[0m937.4    \u001b[0m | \u001b[0m0.2814   \u001b[0m | \u001b[0m0.2504   \u001b[0m | \u001b[0m63.97    \u001b[0m | \u001b[0m1.087    \u001b[0m | \u001b[0m2.388    \u001b[0m | \u001b[0m0.5545   \u001b[0m | \u001b[0m11.19    \u001b[0m | \u001b[0m0.7159   \u001b[0m | \u001b[0m0.1898   \u001b[0m |\n",
            "119/119 [==============================] - 0s 483us/step\n",
            "119/119 [==============================] - 0s 500us/step\n",
            "119/119 [==============================] - 0s 483us/step\n",
            "119/119 [==============================] - 1s 517us/step\n",
            "119/119 [==============================] - 0s 483us/step\n",
            "| \u001b[0m9        \u001b[0m | \u001b[0m2.224e+13\u001b[0m | \u001b[0m0.745    \u001b[0m | \u001b[0m703.5    \u001b[0m | \u001b[0m0.3622   \u001b[0m | \u001b[0m0.1881   \u001b[0m | \u001b[0m61.19    \u001b[0m | \u001b[0m4.58     \u001b[0m | \u001b[0m3.075    \u001b[0m | \u001b[0m0.6113   \u001b[0m | \u001b[0m52.73    \u001b[0m | \u001b[0m0.7096   \u001b[0m | \u001b[0m0.1152   \u001b[0m |\n",
            "119/119 [==============================] - 0s 457us/step\n",
            "119/119 [==============================] - 0s 458us/step\n",
            "119/119 [==============================] - 0s 458us/step\n",
            "119/119 [==============================] - 0s 446us/step\n",
            "119/119 [==============================] - 0s 450us/step\n",
            "| \u001b[0m10       \u001b[0m | \u001b[0m2.224e+13\u001b[0m | \u001b[0m0.7355   \u001b[0m | \u001b[0m902.4    \u001b[0m | \u001b[0m0.5191   \u001b[0m | \u001b[0m0.2041   \u001b[0m | \u001b[0m54.84    \u001b[0m | \u001b[0m4.887    \u001b[0m | \u001b[0m2.461    \u001b[0m | \u001b[0m0.6265   \u001b[0m | \u001b[0m33.25    \u001b[0m | \u001b[0m0.6813   \u001b[0m | \u001b[0m0.8766   \u001b[0m |\n",
            "119/119 [==============================] - 0s 433us/step\n",
            "119/119 [==============================] - 0s 448us/step\n",
            "119/119 [==============================] - 0s 450us/step\n",
            "119/119 [==============================] - 0s 450us/step\n",
            "119/119 [==============================] - 0s 444us/step\n",
            "| \u001b[0m11       \u001b[0m | \u001b[0m2.224e+13\u001b[0m | \u001b[0m0.2498   \u001b[0m | \u001b[0m314.1    \u001b[0m | \u001b[0m0.8254   \u001b[0m | \u001b[0m0.1396   \u001b[0m | \u001b[0m47.05    \u001b[0m | \u001b[0m4.735    \u001b[0m | \u001b[0m2.818    \u001b[0m | \u001b[0m0.4993   \u001b[0m | \u001b[0m14.13    \u001b[0m | \u001b[0m0.119    \u001b[0m | \u001b[0m0.538    \u001b[0m |\n",
            "119/119 [==============================] - 0s 488us/step\n",
            "119/119 [==============================] - 0s 475us/step\n",
            "119/119 [==============================] - 0s 502us/step\n",
            "119/119 [==============================] - 0s 509us/step\n",
            "119/119 [==============================] - 0s 500us/step\n",
            "| \u001b[0m12       \u001b[0m | \u001b[0m2.223e+13\u001b[0m | \u001b[0m0.06424  \u001b[0m | \u001b[0m440.4    \u001b[0m | \u001b[0m0.3781   \u001b[0m | \u001b[0m0.1827   \u001b[0m | \u001b[0m85.91    \u001b[0m | \u001b[0m1.732    \u001b[0m | \u001b[0m4.148    \u001b[0m | \u001b[0m0.3183   \u001b[0m | \u001b[0m79.44    \u001b[0m | \u001b[0m0.9149   \u001b[0m | \u001b[0m0.2263   \u001b[0m |\n",
            "119/119 [==============================] - 0s 483us/step\n",
            "119/119 [==============================] - 0s 500us/step\n",
            "119/119 [==============================] - 0s 492us/step\n",
            "119/119 [==============================] - 0s 507us/step\n",
            "119/119 [==============================] - 0s 534us/step\n",
            "| \u001b[0m13       \u001b[0m | \u001b[0m2.224e+13\u001b[0m | \u001b[0m0.9912   \u001b[0m | \u001b[0m449.2    \u001b[0m | \u001b[0m0.8856   \u001b[0m | \u001b[0m0.2081   \u001b[0m | \u001b[0m24.36    \u001b[0m | \u001b[0m1.807    \u001b[0m | \u001b[0m4.437    \u001b[0m | \u001b[0m0.6641   \u001b[0m | \u001b[0m88.55    \u001b[0m | \u001b[0m0.7237   \u001b[0m | \u001b[0m0.09194  \u001b[0m |\n",
            "119/119 [==============================] - 0s 441us/step\n",
            "119/119 [==============================] - 0s 441us/step\n",
            "119/119 [==============================] - 0s 433us/step\n",
            "119/119 [==============================] - 0s 441us/step\n",
            "119/119 [==============================] - 0s 458us/step\n",
            "| \u001b[0m14       \u001b[0m | \u001b[0m2.223e+13\u001b[0m | \u001b[0m0.03175  \u001b[0m | \u001b[0m345.6    \u001b[0m | \u001b[0m0.2761   \u001b[0m | \u001b[0m0.202    \u001b[0m | \u001b[0m65.64    \u001b[0m | \u001b[0m2.509    \u001b[0m | \u001b[0m2.138    \u001b[0m | \u001b[0m0.2106   \u001b[0m | \u001b[0m39.78    \u001b[0m | \u001b[0m0.3645   \u001b[0m | \u001b[0m0.2026   \u001b[0m |\n",
            "119/119 [==============================] - 0s 500us/step\n",
            "119/119 [==============================] - 0s 492us/step\n",
            "119/119 [==============================] - 0s 517us/step\n",
            "119/119 [==============================] - 0s 517us/step\n",
            "119/119 [==============================] - 0s 500us/step\n",
            "| \u001b[0m15       \u001b[0m | \u001b[0m2.224e+13\u001b[0m | \u001b[0m0.6069   \u001b[0m | \u001b[0m250.4    \u001b[0m | \u001b[0m0.7315   \u001b[0m | \u001b[0m0.2202   \u001b[0m | \u001b[0m67.21    \u001b[0m | \u001b[0m3.868    \u001b[0m | \u001b[0m3.853    \u001b[0m | \u001b[0m0.7781   \u001b[0m | \u001b[0m71.56    \u001b[0m | \u001b[0m0.7979   \u001b[0m | \u001b[0m0.589    \u001b[0m |\n",
            "119/119 [==============================] - 0s 492us/step\n",
            "119/119 [==============================] - 0s 475us/step\n",
            "119/119 [==============================] - 0s 450us/step\n",
            "119/119 [==============================] - 0s 458us/step\n",
            "119/119 [==============================] - 0s 450us/step\n",
            "| \u001b[0m16       \u001b[0m | \u001b[0m2.222e+13\u001b[0m | \u001b[0m0.8611   \u001b[0m | \u001b[0m553.8    \u001b[0m | \u001b[0m0.388    \u001b[0m | \u001b[0m0.08434  \u001b[0m | \u001b[0m27.63    \u001b[0m | \u001b[0m2.734    \u001b[0m | \u001b[0m3.705    \u001b[0m | \u001b[0m0.2582   \u001b[0m | \u001b[0m40.57    \u001b[0m | \u001b[0m0.6354   \u001b[0m | \u001b[0m0.681    \u001b[0m |\n",
            "119/119 [==============================] - 0s 500us/step\n",
            "119/119 [==============================] - 0s 509us/step\n",
            "119/119 [==============================] - 0s 500us/step\n",
            "119/119 [==============================] - 0s 513us/step\n",
            "119/119 [==============================] - 0s 551us/step\n",
            "| \u001b[0m17       \u001b[0m | \u001b[0m2.224e+13\u001b[0m | \u001b[0m0.3567   \u001b[0m | \u001b[0m604.8    \u001b[0m | \u001b[0m0.4119   \u001b[0m | \u001b[0m0.2227   \u001b[0m | \u001b[0m31.6     \u001b[0m | \u001b[0m3.925    \u001b[0m | \u001b[0m3.062    \u001b[0m | \u001b[0m0.3393   \u001b[0m | \u001b[0m93.31    \u001b[0m | \u001b[0m0.9734   \u001b[0m | \u001b[0m0.5595   \u001b[0m |\n",
            "119/119 [==============================] - 1s 594us/step\n",
            "119/119 [==============================] - 0s 543us/step\n",
            "119/119 [==============================] - 0s 560us/step\n",
            "119/119 [==============================] - 0s 543us/step\n",
            "119/119 [==============================] - 0s 583us/step\n",
            "| \u001b[0m18       \u001b[0m | \u001b[0m2.224e+13\u001b[0m | \u001b[0m0.1109   \u001b[0m | \u001b[0m737.7    \u001b[0m | \u001b[0m0.9307   \u001b[0m | \u001b[0m0.08556  \u001b[0m | \u001b[0m29.43    \u001b[0m | \u001b[0m4.402    \u001b[0m | \u001b[0m3.782    \u001b[0m | \u001b[0m0.9006   \u001b[0m | \u001b[0m94.77    \u001b[0m | \u001b[0m0.5163   \u001b[0m | \u001b[0m0.6949   \u001b[0m |\n",
            "119/119 [==============================] - 0s 433us/step\n",
            "119/119 [==============================] - 0s 424us/step\n",
            "119/119 [==============================] - 0s 441us/step\n",
            "119/119 [==============================] - 0s 433us/step\n",
            "119/119 [==============================] - 0s 458us/step\n",
            "| \u001b[0m19       \u001b[0m | \u001b[0m2.22e+13 \u001b[0m | \u001b[0m0.4372   \u001b[0m | \u001b[0m899.2    \u001b[0m | \u001b[0m0.6551   \u001b[0m | \u001b[0m0.02753  \u001b[0m | \u001b[0m43.47    \u001b[0m | \u001b[0m2.187    \u001b[0m | \u001b[0m2.334    \u001b[0m | \u001b[0m0.1267   \u001b[0m | \u001b[0m63.06    \u001b[0m | \u001b[0m0.4873   \u001b[0m | \u001b[0m0.1037   \u001b[0m |\n",
            "119/119 [==============================] - 0s 450us/step\n",
            "119/119 [==============================] - 0s 464us/step\n",
            "119/119 [==============================] - 0s 492us/step\n",
            "119/119 [==============================] - 0s 458us/step\n",
            "119/119 [==============================] - 0s 450us/step\n",
            "| \u001b[0m20       \u001b[0m | \u001b[0m2.22e+13 \u001b[0m | \u001b[0m0.3013   \u001b[0m | \u001b[0m701.7    \u001b[0m | \u001b[0m0.07346  \u001b[0m | \u001b[0m0.05054  \u001b[0m | \u001b[0m76.62    \u001b[0m | \u001b[0m3.378    \u001b[0m | \u001b[0m3.057    \u001b[0m | \u001b[0m0.54     \u001b[0m | \u001b[0m33.33    \u001b[0m | \u001b[0m0.6661   \u001b[0m | \u001b[0m0.02819  \u001b[0m |\n",
            "119/119 [==============================] - 1s 458us/step\n",
            "119/119 [==============================] - 0s 450us/step\n",
            "119/119 [==============================] - 0s 458us/step\n",
            "119/119 [==============================] - 0s 483us/step\n",
            "119/119 [==============================] - 0s 458us/step\n",
            "| \u001b[0m21       \u001b[0m | \u001b[0m2.223e+13\u001b[0m | \u001b[0m0.6874   \u001b[0m | \u001b[0m667.3    \u001b[0m | \u001b[0m0.5589   \u001b[0m | \u001b[0m0.04195  \u001b[0m | \u001b[0m30.23    \u001b[0m | \u001b[0m3.178    \u001b[0m | \u001b[0m3.264    \u001b[0m | \u001b[0m0.8174   \u001b[0m | \u001b[0m41.98    \u001b[0m | \u001b[0m0.5924   \u001b[0m | \u001b[0m0.6753   \u001b[0m |\n",
            "119/119 [==============================] - 0s 441us/step\n",
            "119/119 [==============================] - 0s 458us/step\n",
            "119/119 [==============================] - 0s 458us/step\n",
            "119/119 [==============================] - 0s 475us/step\n",
            "119/119 [==============================] - 0s 458us/step\n",
            "| \u001b[0m22       \u001b[0m | \u001b[0m2.224e+13\u001b[0m | \u001b[0m0.09972  \u001b[0m | \u001b[0m783.9    \u001b[0m | \u001b[0m0.7164   \u001b[0m | \u001b[0m0.2642   \u001b[0m | \u001b[0m53.48    \u001b[0m | \u001b[0m1.875    \u001b[0m | \u001b[0m3.743    \u001b[0m | \u001b[0m0.9643   \u001b[0m | \u001b[0m61.84    \u001b[0m | \u001b[0m0.2376   \u001b[0m | \u001b[0m0.3408   \u001b[0m |\n",
            "119/119 [==============================] - 0s 458us/step\n",
            "119/119 [==============================] - 0s 450us/step\n",
            "119/119 [==============================] - 0s 460us/step\n",
            "119/119 [==============================] - 0s 452us/step\n",
            "119/119 [==============================] - 0s 458us/step\n",
            "| \u001b[0m23       \u001b[0m | \u001b[0m2.223e+13\u001b[0m | \u001b[0m0.6347   \u001b[0m | \u001b[0m741.3    \u001b[0m | \u001b[0m0.6444   \u001b[0m | \u001b[0m0.201    \u001b[0m | \u001b[0m66.52    \u001b[0m | \u001b[0m2.763    \u001b[0m | \u001b[0m3.407    \u001b[0m | \u001b[0m0.3842   \u001b[0m | \u001b[0m33.18    \u001b[0m | \u001b[0m0.9529   \u001b[0m | \u001b[0m0.5877   \u001b[0m |\n",
            "119/119 [==============================] - 0s 500us/step\n",
            "119/119 [==============================] - 0s 492us/step\n",
            "119/119 [==============================] - 0s 509us/step\n",
            "119/119 [==============================] - 0s 496us/step\n",
            "119/119 [==============================] - 0s 823us/step\n",
            "| \u001b[0m24       \u001b[0m | \u001b[0m2.224e+13\u001b[0m | \u001b[0m0.826    \u001b[0m | \u001b[0m594.4    \u001b[0m | \u001b[0m0.681    \u001b[0m | \u001b[0m0.1518   \u001b[0m | \u001b[0m38.07    \u001b[0m | \u001b[0m2.38     \u001b[0m | \u001b[0m4.119    \u001b[0m | \u001b[0m0.1059   \u001b[0m | \u001b[0m83.26    \u001b[0m | \u001b[0m0.1024   \u001b[0m | \u001b[0m0.6199   \u001b[0m |\n",
            "119/119 [==============================] - 0s 475us/step\n",
            "119/119 [==============================] - 0s 458us/step\n",
            "119/119 [==============================] - 0s 433us/step\n",
            "119/119 [==============================] - 0s 433us/step\n",
            "119/119 [==============================] - 0s 467us/step\n",
            "| \u001b[0m25       \u001b[0m | \u001b[0m2.224e+13\u001b[0m | \u001b[0m0.08354  \u001b[0m | \u001b[0m976.4    \u001b[0m | \u001b[0m0.6527   \u001b[0m | \u001b[0m0.2858   \u001b[0m | \u001b[0m76.45    \u001b[0m | \u001b[0m1.421    \u001b[0m | \u001b[0m2.57     \u001b[0m | \u001b[0m0.7721   \u001b[0m | \u001b[0m61.96    \u001b[0m | \u001b[0m0.3429   \u001b[0m | \u001b[0m0.02441  \u001b[0m |\n",
            "119/119 [==============================] - 0s 467us/step\n",
            "119/119 [==============================] - 0s 458us/step\n",
            "119/119 [==============================] - 0s 458us/step\n",
            "119/119 [==============================] - 0s 458us/step\n",
            "119/119 [==============================] - 0s 433us/step\n",
            "| \u001b[0m26       \u001b[0m | \u001b[0m2.224e+13\u001b[0m | \u001b[0m0.1708   \u001b[0m | \u001b[0m976.7    \u001b[0m | \u001b[0m0.5972   \u001b[0m | \u001b[0m0.281    \u001b[0m | \u001b[0m75.48    \u001b[0m | \u001b[0m1.768    \u001b[0m | \u001b[0m2.324    \u001b[0m | \u001b[0m0.7635   \u001b[0m | \u001b[0m74.95    \u001b[0m | \u001b[0m0.391    \u001b[0m | \u001b[0m0.1551   \u001b[0m |\n",
            "119/119 [==============================] - 0s 458us/step\n",
            "119/119 [==============================] - 0s 450us/step\n",
            "119/119 [==============================] - 0s 450us/step\n",
            "119/119 [==============================] - 0s 433us/step\n",
            "119/119 [==============================] - 0s 460us/step\n",
            "| \u001b[0m27       \u001b[0m | \u001b[0m2.224e+13\u001b[0m | \u001b[0m0.2591   \u001b[0m | \u001b[0m703.8    \u001b[0m | \u001b[0m0.9316   \u001b[0m | \u001b[0m0.2437   \u001b[0m | \u001b[0m51.9     \u001b[0m | \u001b[0m3.185    \u001b[0m | \u001b[0m2.981    \u001b[0m | \u001b[0m0.2125   \u001b[0m | \u001b[0m66.93    \u001b[0m | \u001b[0m0.3255   \u001b[0m | \u001b[0m0.5235   \u001b[0m |\n",
            "119/119 [==============================] - 0s 467us/step\n",
            "119/119 [==============================] - 0s 475us/step\n",
            "119/119 [==============================] - 0s 500us/step\n",
            "119/119 [==============================] - 0s 475us/step\n",
            "119/119 [==============================] - 0s 475us/step\n",
            "| \u001b[0m28       \u001b[0m | \u001b[0m2.224e+13\u001b[0m | \u001b[0m0.3892   \u001b[0m | \u001b[0m500.6    \u001b[0m | \u001b[0m0.3151   \u001b[0m | \u001b[0m0.2818   \u001b[0m | \u001b[0m54.05    \u001b[0m | \u001b[0m4.182    \u001b[0m | \u001b[0m3.065    \u001b[0m | \u001b[0m0.6589   \u001b[0m | \u001b[0m79.59    \u001b[0m | \u001b[0m0.4654   \u001b[0m | \u001b[0m0.8931   \u001b[0m |\n",
            "119/119 [==============================] - 0s 458us/step\n",
            "119/119 [==============================] - 0s 458us/step\n",
            "119/119 [==============================] - 0s 450us/step\n",
            "119/119 [==============================] - 0s 475us/step\n",
            "119/119 [==============================] - 0s 458us/step\n",
            "| \u001b[0m29       \u001b[0m | \u001b[0m2.224e+13\u001b[0m | \u001b[0m0.5135   \u001b[0m | \u001b[0m475.3    \u001b[0m | \u001b[0m0.8292   \u001b[0m | \u001b[0m0.1875   \u001b[0m | \u001b[0m46.04    \u001b[0m | \u001b[0m3.281    \u001b[0m | \u001b[0m1.14     \u001b[0m | \u001b[0m0.7166   \u001b[0m | \u001b[0m82.17    \u001b[0m | \u001b[0m0.8091   \u001b[0m | \u001b[0m0.6463   \u001b[0m |\n",
            "=============================================================================================================================================================\n"
          ]
        }
      ],
      "source": [
        "params_nn4 ={\n",
        "    'neurons': (10, 100),\n",
        "    'activation':(0.01, 1),\n",
        "    'optimizer':(0,1),\n",
        "    'learning_rate':(0.01, 1),\n",
        "    'batch_size':(200, 1000),\n",
        "    'epochs':(20, 100),\n",
        "    'layers1':(1,5),\n",
        "    'layers2':(1,5),\n",
        "    'normalization':(0,1),\n",
        "    'dropout':(0,1),\n",
        "    'dropout_rate':(0,0.3)\n",
        "}\n",
        "# Run Bayesian Optimization\n",
        "nn_bo4 = BayesianOptimization(function4, params_nn4, random_state=2023)\n",
        "nn_bo4.maximize(init_points=25, n_iter=4)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f2bf093c",
      "metadata": {
        "id": "f2bf093c"
      },
      "source": [
        "**BEST PARAMS**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6fe776ef",
      "metadata": {
        "id": "6fe776ef",
        "outputId": "e7b55fee-f91d-4211-d478-f3d93abcfa90"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'activation': 'relu',\n",
              " 'batch_size': 978,\n",
              " 'dropout': 0.41131105432155857,\n",
              " 'dropout_rate': 0.21649932098793595,\n",
              " 'epochs': 73,\n",
              " 'layers1': 2,\n",
              " 'layers2': 2,\n",
              " 'learning_rate': 0.732481446371382,\n",
              " 'neurons': 88,\n",
              " 'normalization': 0.39172036421755163,\n",
              " 'optimizer': <keras.optimizers.legacy.adam.Adam at 0x121871249a0>}"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "params_nn_4 = nn_bo4.max['params']\n",
        "learning_rate = params_nn_4['learning_rate']\n",
        "activationL = ['relu', 'relu']\n",
        "params_nn_4['activation'] = activationL[round(params_nn_4['activation'])]\n",
        "params_nn_4['batch_size'] = round(params_nn_4['batch_size'])\n",
        "params_nn_4['epochs'] = round(params_nn_4['epochs'])\n",
        "params_nn_4['layers1'] = round(params_nn_4['layers1'])\n",
        "params_nn_4['layers2'] = round(params_nn_4['layers2'])\n",
        "params_nn_4['neurons'] = round(params_nn_4['neurons'])\n",
        "optimizerL = ['Adam', 'Adam']\n",
        "optimizerD= {'Adam':Adam(lr=learning_rate)}\n",
        "params_nn_4['optimizer'] = optimizerD[optimizerL[round(params_nn_4['optimizer'])]]\n",
        "params_nn_4"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "03b8b4fc",
      "metadata": {
        "id": "03b8b4fc"
      },
      "source": [
        "**MODEL**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6574c846",
      "metadata": {
        "scrolled": true,
        "id": "6574c846",
        "outputId": "022721e1-cca9-4a7d-f905-d48db0b3c616"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/73\n",
            "20/20 [==============================] - 1s 2ms/step - loss: 23847170473984.0000 - mse: 23847170473984.0000\n",
            "Epoch 2/73\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 23623658110976.0000 - mse: 23623658110976.0000\n",
            "Epoch 3/73\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 22265781551104.0000 - mse: 22265779453952.0000\n",
            "Epoch 4/73\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 21510521618432.0000 - mse: 21510521618432.0000\n",
            "Epoch 5/73\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 21399873781760.0000 - mse: 21399873781760.0000\n",
            "Epoch 6/73\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 21340337733632.0000 - mse: 21340337733632.0000\n",
            "Epoch 7/73\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 21259559632896.0000 - mse: 21259561730048.0000\n",
            "Epoch 8/73\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 21156272799744.0000 - mse: 21156272799744.0000\n",
            "Epoch 9/73\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 21010229231616.0000 - mse: 21010229231616.0000\n",
            "Epoch 10/73\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 20692911259648.0000 - mse: 20692911259648.0000\n",
            "Epoch 11/73\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 20258767241216.0000 - mse: 20258767241216.0000\n",
            "Epoch 12/73\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 19175112179712.0000 - mse: 19175112179712.0000\n",
            "Epoch 13/73\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 16796354609152.0000 - mse: 16796354609152.0000\n",
            "Epoch 14/73\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 13514777296896.0000 - mse: 13514777296896.0000\n",
            "Epoch 15/73\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 8552532410368.0000 - mse: 8552532410368.0000\n",
            "Epoch 16/73\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 8887629512704.0000 - mse: 8887629512704.0000\n",
            "Epoch 17/73\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 7976703229952.0000 - mse: 7976703229952.0000\n",
            "Epoch 18/73\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 7810151612416.0000 - mse: 7810151612416.0000\n",
            "Epoch 19/73\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 7731939377152.0000 - mse: 7731939377152.0000\n",
            "Epoch 20/73\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 7877363236864.0000 - mse: 7877363236864.0000\n",
            "Epoch 21/73\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 7906658353152.0000 - mse: 7906658353152.0000\n",
            "Epoch 22/73\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 7713996144640.0000 - mse: 7713996144640.0000\n",
            "Epoch 23/73\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 7735708483584.0000 - mse: 7735708483584.0000\n",
            "Epoch 24/73\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 7486636556288.0000 - mse: 7486636556288.0000\n",
            "Epoch 25/73\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 7691637358592.0000 - mse: 7691637358592.0000\n",
            "Epoch 26/73\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 8015428190208.0000 - mse: 8015428190208.0000\n",
            "Epoch 27/73\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 7562930946048.0000 - mse: 7562930946048.0000\n",
            "Epoch 28/73\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 7624917516288.0000 - mse: 7624917516288.0000\n",
            "Epoch 29/73\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 7551751028736.0000 - mse: 7551751028736.0000\n",
            "Epoch 30/73\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 7558890258432.0000 - mse: 7558890258432.0000\n",
            "Epoch 31/73\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 7412935294976.0000 - mse: 7412935294976.0000\n",
            "Epoch 32/73\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 7574920364032.0000 - mse: 7574920364032.0000\n",
            "Epoch 33/73\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 7347708624896.0000 - mse: 7347708624896.0000\n",
            "Epoch 34/73\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 7450696089600.0000 - mse: 7450696089600.0000\n",
            "Epoch 35/73\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 7900273573888.0000 - mse: 7900273573888.0000\n",
            "Epoch 36/73\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 7251040927744.0000 - mse: 7251040927744.0000\n",
            "Epoch 37/73\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 7281239392256.0000 - mse: 7281239392256.0000\n",
            "Epoch 38/73\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 7137277771776.0000 - mse: 7137278296064.0000\n",
            "Epoch 39/73\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 7219928104960.0000 - mse: 7219928104960.0000\n",
            "Epoch 40/73\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 7261349478400.0000 - mse: 7261349478400.0000\n",
            "Epoch 41/73\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 7218989629440.0000 - mse: 7218989629440.0000\n",
            "Epoch 42/73\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 7123304972288.0000 - mse: 7123304972288.0000\n",
            "Epoch 43/73\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 7138100903936.0000 - mse: 7138100903936.0000\n",
            "Epoch 44/73\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 6993767563264.0000 - mse: 6993767563264.0000\n",
            "Epoch 45/73\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 7021206700032.0000 - mse: 7021206700032.0000\n",
            "Epoch 46/73\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 7180743868416.0000 - mse: 7180743868416.0000\n",
            "Epoch 47/73\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 7047205093376.0000 - mse: 7047205093376.0000\n",
            "Epoch 48/73\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 7391356649472.0000 - mse: 7391356649472.0000\n",
            "Epoch 49/73\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 7015239254016.0000 - mse: 7015239254016.0000\n",
            "Epoch 50/73\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 7128654282752.0000 - mse: 7128654282752.0000\n",
            "Epoch 51/73\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 7173014814720.0000 - mse: 7173014814720.0000\n",
            "Epoch 52/73\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 6935566876672.0000 - mse: 6935566876672.0000\n",
            "Epoch 53/73\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 6833102651392.0000 - mse: 6833102651392.0000\n",
            "Epoch 54/73\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 6929476747264.0000 - mse: 6929476747264.0000\n",
            "Epoch 55/73\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 6960962338816.0000 - mse: 6960962338816.0000\n",
            "Epoch 56/73\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 6833444487168.0000 - mse: 6833444487168.0000\n",
            "Epoch 57/73\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 6622470995968.0000 - mse: 6622470995968.0000\n",
            "Epoch 58/73\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 6908901588992.0000 - mse: 6908901588992.0000\n",
            "Epoch 59/73\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 7074739126272.0000 - mse: 7074739126272.0000\n",
            "Epoch 60/73\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 6506977165312.0000 - mse: 6506977165312.0000\n",
            "Epoch 61/73\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 6643885015040.0000 - mse: 6643885015040.0000\n",
            "Epoch 62/73\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 6748646670336.0000 - mse: 6748646670336.0000\n",
            "Epoch 63/73\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 6714085081088.0000 - mse: 6714085081088.0000\n",
            "Epoch 64/73\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 6654034182144.0000 - mse: 6654034182144.0000\n",
            "Epoch 65/73\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 7091108446208.0000 - mse: 7091108446208.0000\n",
            "Epoch 66/73\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 6658280914944.0000 - mse: 6658280390656.0000\n",
            "Epoch 67/73\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 6694733086720.0000 - mse: 6694733086720.0000\n",
            "Epoch 68/73\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 6595213787136.0000 - mse: 6595213787136.0000\n",
            "Epoch 69/73\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 6541915193344.0000 - mse: 6541915193344.0000\n",
            "Epoch 70/73\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 6496852639744.0000 - mse: 6496852639744.0000\n",
            "Epoch 71/73\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 6491017314304.0000 - mse: 6491017314304.0000\n",
            "Epoch 72/73\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 6607783067648.0000 - mse: 6607783067648.0000\n",
            "Epoch 73/73\n",
            "20/20 [==============================] - 0s 2ms/step - loss: 6457799999488.0000 - mse: 6457799999488.0000\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x12191043220>"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_4 = Sequential()\n",
        "model_4.add(Dense(params_nn_4['neurons'], input_dim=21, activation=params_nn_4['activation']))\n",
        "if params_nn_4['normalization'] > 0.5:\n",
        "    model_4.add(BatchNormalization())\n",
        "for i in range(params_nn_4['layers1']):\n",
        "    model_4.add(Dense(params_nn_4['neurons'], activation=params_nn_4['activation']))\n",
        "if params_nn_4['dropout'] > 0.5:\n",
        "    model_4.add(Dropout(params_nn_4['dropout_rate'], seed=2023))\n",
        "for i in range(params_nn_4['layers2']):\n",
        "    model_4.add(Dense(params_nn_4['neurons'], activation=params_nn_4['activation']))\n",
        "model_4.add(Dense(1))\n",
        "model_4.compile(loss='mse', optimizer='adam', metrics=['mse'])\n",
        "    \n",
        "model_4.fit(X_train_mi_reg_df, y_train, epochs=params_nn_4['epochs'], batch_size=params_nn_4['batch_size'],verbose=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "282d675e",
      "metadata": {
        "id": "282d675e"
      },
      "source": [
        "**EVALUATION**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ede6c518",
      "metadata": {
        "id": "ede6c518",
        "outputId": "13e3e338-a929-4a13-bd58-3eb58ca4f135"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "149/149 [==============================] - 0s 426us/step\n",
            "Standard Deviation: price    5.275527e+06\n",
            "dtype: float64\n",
            "Range: price    342535000\n",
            "dtype: int64\n",
            "Mean squared error: 7424866286318.158\n",
            "Mean absolute error: 402564.63379297615\n",
            "RMSE: 2724860.7829241767\n",
            "R-squared: 0.7331614935833962\n",
            "Percentage of error compared to SD: price    7.630794\n",
            "dtype: float64\n"
          ]
        }
      ],
      "source": [
        "X_test_mi_reg_df = pd.DataFrame(X_test_mi_reg_arr)\n",
        "predicted_prices4 = model_4.predict(X_test_mi_reg_df)\n",
        "mse4 = mean_squared_error(y_test, predicted_prices4)\n",
        "\n",
        "rmse4 = mean_squared_error(y_test, predicted_prices4, squared=False)\n",
        "\n",
        "# Calculate mean absolute error\n",
        "mae4 = mean_absolute_error(y_test, predicted_prices4)\n",
        "\n",
        "# Calculate coefficient of determination (R-squared)\n",
        "r2_4 = r2_score(y_test, predicted_prices4)\n",
        "\n",
        "print('Standard Deviation:', y_test.std())\n",
        "print('Range:', y_test.max() - y_test.min())\n",
        "print('Mean squared error:', mse4)\n",
        "print('Mean absolute error:', mae4)\n",
        "print('RMSE:', rmse4)\n",
        "print('R-squared:', r2_4)\n",
        "print('Percentage of error compared to SD:', mae4/y_test.std() * 100)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0d690312",
      "metadata": {
        "id": "0d690312"
      },
      "source": [
        "# EVALUATIONS COMBINED"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "64ac53eb",
      "metadata": {
        "id": "64ac53eb",
        "outputId": "4c64b155-c942-46c0-b156-d3c4bd92b8c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Standard Deviation: price    5.275527e+06\n",
            "dtype: float64\n",
            "Range: price    342535000\n",
            "dtype: int64\n",
            "\n",
            "Scaled Training Data: Mean squared error: 17739932846785.258\n",
            "Scaled Training Data: Mean absolute error: 449198.51814622444\n",
            "Scaled Training Data: RMSE: 4211879.965856726\n",
            "Scaled Training Data: R-squared: 0.36245354431636856\n",
            "Scaled Training Data: RRMSE: price    0.798381\n",
            "dtype: float64\n",
            "\n",
            "SelectKBest F Regressor: Mean squared error: 900300898706.1031\n",
            "SelectKBest F Regressor: Mean absolute error: 459639.27273386414\n",
            "SelectKBest F Regressor: RMSE: 948841.8723402247\n",
            "SelectKBest F Regressor: R-squared: 0.9676445422890719\n",
            "SelectKBest F Regressor: RRMSE: price    0.179857\n",
            "dtype: float64\n",
            "\n",
            "SelectKBest Mutual Info Regressor: Mean squared error: 7424866286318.158\n",
            "SelectKBest Mutual Info Regressor: Mean absolute error: 402564.63379297615\n",
            "SelectKBest Mutual Info Regressor: RMSE: 2724860.7829241767\n",
            "SelectKBest Mutual Info Regressor: R-squared: 0.7331614935833962\n",
            "SelectKBest Mutual Info Regressor: RRMSE: price    0.51651\n",
            "dtype: float64\n"
          ]
        }
      ],
      "source": [
        "print('Standard Deviation:', y_test.std())\n",
        "print('Range:', y_test.max() - y_test.min())\n",
        "\n",
        "print('\\nScaled Training Data: Mean squared error:', mse2)\n",
        "print('Scaled Training Data: Mean absolute error:', mae2)\n",
        "print('Scaled Training Data: RMSE:', rmse2)\n",
        "print('Scaled Training Data: R-squared:', r2_2)\n",
        "print('Scaled Training Data: RRMSE:', rmse2/y_test.std())\n",
        "\n",
        "print('\\nSelectKBest F Regressor: Mean squared error:', mse3)\n",
        "print('SelectKBest F Regressor: Mean absolute error:', mae3)\n",
        "print('SelectKBest F Regressor: RMSE:', rmse3)\n",
        "print('SelectKBest F Regressor: R-squared:', r2_3)\n",
        "print('SelectKBest F Regressor: RRMSE:', rmse3/y_test.std())\n",
        "\n",
        "print('\\nSelectKBest Mutual Info Regressor: Mean squared error:', mse4)\n",
        "print('SelectKBest Mutual Info Regressor: Mean absolute error:', mae4)\n",
        "print('SelectKBest Mutual Info Regressor: RMSE:', rmse4)\n",
        "print('SelectKBest Mutual Info Regressor: R-squared:', r2_4)\n",
        "print('SelectKBest Mutual Info Regressor: RRMSE:', rmse4/y_test.std())"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}